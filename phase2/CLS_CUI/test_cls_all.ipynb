{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clinical-sts-test-part2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOQowums6HHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a10e4dd-8e81-42b6-cc13-6e3646a8bcd8"
      },
      "source": [
        "!pip install nlp transformers texttable &> /dev/null\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Optional\n",
        "from typing import List\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)  \n",
        "from texttable import Texttable\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset, IterableDataset\n",
        "from transformers import BertModel, BertTokenizer, AutoTokenizer, AutoModel, BertConfig, \\\n",
        "     AdamW, set_seed, AutoConfig, PreTrainedTokenizer, DataCollator, PreTrainedModel, PreTrainedTokenizer, DataCollator, PreTrainedModel\n",
        "\n",
        "set_seed(23)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvGxZxwPRzij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d925d6-e333-4e15-f506-c749a1324c90"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL-KqYLf6Ld7"
      },
      "source": [
        "# Class to store data samples, text_a, text_b\n",
        "@dataclass\n",
        "class Example:\n",
        "    text_a: str\n",
        "    text_b: str\n",
        "    cui_embedding_a: list\n",
        "    cui_embedding_b: list\n",
        "\n",
        "\n",
        "# lowercase and add space around words, remove unnecessary spaces\n",
        "def pre_process(sentence, cased=False):\n",
        "    sentence = sentence.replace(\":\", \" : \").replace(\"/\", \" / \")\\\n",
        "               .replace(\"[\", \" [ \").replace(\"]\", \" ] \").replace(\"(\", \" ( \")\\\n",
        "               .replace(\")\", \" ) \").replace(\"\\\"\", \" \\\" \").replace(\"-\", \" - \")\\\n",
        "               .replace(\"?\", \" \").lstrip().rstrip()\n",
        "    if cased:\n",
        "      return re.sub(' +',' ', sentence)\n",
        "    return re.sub(' +',' ', sentence).lower()\n",
        "\n",
        "\n",
        "# returns test and train arrays as Example Objects\n",
        "# test train split is stratified and 80-20 split\n",
        "def get_test_data(cased=False):\n",
        "    train_data = \"/content/drive/My Drive/clinical-sts/augmented_test_with_cui_embeddings.tsv\"\n",
        "    df = pd.read_csv(train_data, sep=\"\\t\", names=[\"sentence_1\", \"sentence_2\", \"gold_score\", \"label\", \"cuis_1\", \"cuis_2\", \"cui_embedding_1\", \"cui_embedding_2\"], encoding=\"utf-8\")\n",
        "    df[\"sentence_1\"] = df[\"sentence_1\"].apply(lambda sentence: pre_process(sentence, cased))\n",
        "    df[\"sentence_2\"] = df[\"sentence_2\"].apply(lambda sentence: pre_process(sentence, cased))\n",
        "    df[\"input_sample\"] = df[\"sentence_1\"] + \"<SEP>\" + df[\"sentence_2\"] + \"<SEP>\" + df[\"cui_embedding_1\"] + \"<SEP>\" + df[\"cui_embedding_2\"]\n",
        "\n",
        "    test = [Example(text_a=sample.split(\"<SEP>\")[0], \n",
        "                    text_b=sample.split(\"<SEP>\")[1],\n",
        "                    cui_embedding_a=list(map(float, sample.split(\"<SEP>\")[2].split(\",\"))),\n",
        "                    cui_embedding_b=list(map(float, sample.split(\"<SEP>\")[3].split(\",\")))) for sample in df[\"input_sample\"]]\n",
        "\n",
        "    return test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# DYNAMIC PADDING AND UNIFORM LENGTH BATCHING - reduces wasted computation and makes it faster to run\n",
        "# CODE BORROWED FROM https://towardsdatascience.com/divide-hugging-face-transformers-training-time-by-2-or-more-21bf7129db9q-21bf7129db9e\n",
        "\n",
        "\n",
        "# We'll be creating a custome dataset using this first\n",
        "@dataclass\n",
        "class Features:\n",
        "    og_sample: Example\n",
        "    cui_embedding: List[float]\n",
        "    input_ids: List[int]\n",
        "    attention_mask: List[int]\n",
        "\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenizer, \n",
        "                 pad_to_max_length, \n",
        "                 max_len,\n",
        "                 examples: List[Example]):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.examples: List[Example] = examples\n",
        "        self.current = 0\n",
        "        self.pad_to_max_length = pad_to_max_length\n",
        "\n",
        "    # tokenize the sentences and return a Features object for each sentence \n",
        "    def encode(self, ex: Example) -> Features:\n",
        "        encode_dict = self.tokenizer.encode_plus(text=ex.text_a,\n",
        "                                                 text_pair=ex.text_b,\n",
        "                                                 add_special_tokens=True,\n",
        "                                                 max_length=self.max_len,\n",
        "                                                 pad_to_max_length=self.pad_to_max_length,\n",
        "                                                 return_token_type_ids=False,\n",
        "                                                 return_attention_mask=True,\n",
        "                                                 return_overflowing_tokens=False,\n",
        "                                                 return_special_tokens_mask=False,\n",
        "                                                 truncation=True,\n",
        "                                                 )\n",
        "        return Features(og_sample=ex,\n",
        "                        cui_embedding=ex.cui_embedding_a+ex.cui_embedding_b,\n",
        "                        input_ids=encode_dict[\"input_ids\"],\n",
        "                        attention_mask=encode_dict[\"attention_mask\"])\n",
        "\n",
        "    def __getitem__(self, idx) -> Features:\n",
        "        return self.encode(ex=self.examples[idx])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "\n",
        "def pad_seq(seq: List[int], max_batch_len: int, pad_value: int) -> List[int]:\n",
        "    return seq + (max_batch_len - len(seq)) * [pad_value]\n",
        "\n",
        "\n",
        "# Smart Collator is used to create batches which are dynamically padded with uniform length \n",
        "@dataclass\n",
        "class SmartCollator:  # (DataCollator):\n",
        "    pad_token_id: int\n",
        "\n",
        "    def collate_batch(self, batch: List[Features]) -> Dict[str, torch.Tensor]:\n",
        "        batch_og_sample = list()\n",
        "        batch_cui_embedding = list()\n",
        "        batch_inputs = list()\n",
        "        batch_attention_masks = list()\n",
        "        labels = list()\n",
        "        max_size = max([len(ex.input_ids) for ex in batch])\n",
        "        for item in batch:\n",
        "            batch_inputs += [pad_seq(item.input_ids, max_size, self.pad_token_id)]\n",
        "            batch_attention_masks += [pad_seq(item.attention_mask, max_size, 0)]\n",
        "            batch_og_sample.append(item)\n",
        "            batch_cui_embedding.append(np.array(item.cui_embedding))\n",
        "\n",
        "        return {\"input_ids\": torch.tensor(batch_inputs, dtype=torch.long),\n",
        "                \"attention_mask\": torch.tensor(batch_attention_masks, dtype=torch.long),\n",
        "                \"og_sample\": batch_og_sample,\n",
        "                \"cui_embedding\": torch.tensor(batch_cui_embedding, dtype=torch.float)\n",
        "                }\n",
        "                \n",
        "def collate_wrapper(data):\n",
        "    collator = SmartCollator(pad_token_id=tokenizer.pad_token_id)\n",
        "    return collator.collate_batch(data)\n",
        "\n",
        "\n",
        "# USE THIS FUNCTION TO LOAD TEST AND TRAIN DATA AND ITERATE THROUGH THEM\n",
        "def load_test_data(tokenizer, batch_size, cased=False):\n",
        "    # Get train and test Data Examples\n",
        "    test = get_test_data(cased)\n",
        "\n",
        "    # Now tokenize the words and convert them to token IDs\n",
        "    max_sequence_len = 256\n",
        "    test_set = TextDataset(tokenizer=tokenizer,\n",
        "                            max_len=max_sequence_len,\n",
        "                            examples=test,\n",
        "                            pad_to_max_length=True)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_wrapper,\n",
        "              pin_memory=False, drop_last=False, timeout=0,\n",
        "              worker_init_fn=None)\n",
        "    \n",
        "    return test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QfchdW56MMU"
      },
      "source": [
        "def get_bert_output(my_bert, input_ids, attention_mask):    \n",
        "    outputs = my_bert(input_ids, attention_mask=attention_mask)\n",
        "    hidden_states = outputs[2]\n",
        "    sent_embedding = hidden_states[11][:, 0:1, :].squeeze(1).cuda()\n",
        "    return sent_embedding\n",
        "\n",
        "# def get_bert_token_mean_output(my_bert, input_ids, attention_mask):  \n",
        "#     outputs = my_bert(input_ids, attention_mask=attention_mask)\n",
        "#     token_embeddings = outputs[0][:, 1:, :]\n",
        "#     attention_mask = attention_mask[:, 1:]\n",
        "#     input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "#     sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "#     sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "#     return sum_embeddings / sum_mask\n",
        "\n",
        "\n",
        "'''\n",
        "    Method to predict using a given bert model and its regression head weights\n",
        "'''\n",
        "def get_predictions(model, regression, test_dataloader):\n",
        "    predicted = list()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_data in test_dataloader:\n",
        "            input_ids = batch_data[\"input_ids\"].to(device)\n",
        "            attention_mask = batch_data[\"attention_mask\"].to(device)\n",
        "            cui_embedding = batch_data[\"cui_embedding\"].to(device)\n",
        "\n",
        "            bert_embedding = get_bert_output(model, input_ids, attention_mask)\n",
        "            bert_cui_embedding = torch.cat((bert_embedding, cui_embedding), dim=1)\n",
        "\n",
        "            predicted_score = regression(bert_cui_embedding)\n",
        "            predicted.extend(predicted_score.tolist())\n",
        "    predicted = [item[0] for item in predicted]\n",
        "    return predicted\n",
        "\n",
        "\n",
        "'''\n",
        "    Method to evaluate and calculate pcc on dev/test dataset, and show terrible predictions\n",
        "'''\n",
        "def evaluate_predictions(predictions, actual_scores, test_dataloader, show_bad_predictions=True, prediction_difference=2.0):\n",
        "    correlation, p_value = pearsonr(actual_scores, predictions)\n",
        "    print(\"Test Dataset Pearson Correlation: \", correlation)\n",
        "\n",
        "    if show_bad_predictions:\n",
        "        print(\"BAD EXAMPLES\")\n",
        "        print(\"actual  predicted     difference     SENTENCE\")\n",
        "        for act, pre, test_example in zip(actual_scores, predictions, test_dataloader):\n",
        "            og_text =  test_example['og_sample'][0].og_sample\n",
        "            if abs(pre-act) > prediction_difference:\n",
        "                print(\"{:.2f}    {:.2f}          {:.2f}     {} | {}\".format(act, pre, abs(pre-act), og_text.text_a, og_text.text_b))\n",
        "\n",
        "    show_good_predictions = False\n",
        "    if show_good_predictions:\n",
        "        print(\"GOOD EXAMPLES\")\n",
        "        print(\"actual  predicted     difference     SENTENCE\")\n",
        "        for act, pre, test_example in zip(actual_scores, predictions, test_dataloader):\n",
        "            og_text =  test_example['og_sample'][0].og_sample\n",
        "            if abs(pre-act) < 0.5:\n",
        "                print(\"{:.2f}    {:.2f}          {:.2f}     {} | {}\".format(act, pre, abs(pre-act), og_text.text_a, og_text.text_b))\n",
        "\n",
        "    d = {\"gold_scores\": actual_scores, \"predicted_scores\": predictions}\n",
        "    dx = pd.DataFrame(d)\n",
        "    dx.plot.hist(bins=20, alpha=0.25)\n",
        "\n",
        "\n",
        "def get_optimizer_params(model):\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    opt_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "    return opt_parameters\n",
        "\n",
        "\n",
        "# required to unpickle my linear regression model - same as the one used in train.py\n",
        "# class linearRegression(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(linearRegression, self).__init__()\n",
        "#         self.linear = nn.Linear(768, 1)\n",
        "#     def forward(self, x):\n",
        "#         out = self.linear(x)\n",
        "#         return out\n",
        "\n",
        "class linearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(linearRegression, self).__init__()\n",
        "        self.linear_1 = nn.Sequential(\n",
        "                            nn.Linear(868, 256),\n",
        "                            nn.ReLU())\n",
        "        self.linear_2 = nn.Linear(256, 1)\n",
        "    def forward(self, x):\n",
        "        out = self.linear_1(x)\n",
        "        out = self.linear_2(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeaQdt0q8z7H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "outputId": "6943719b-8f25-4874-ea1b-2d09e46edfd1"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
        "test_dataloader = load_test_data(tokenizer=tokenizer, batch_size=1)\n",
        "\n",
        "my_bert = torch.load(\"/content/drive/My Drive/clinical-sts/models/dnn-bert-bert-base-uncased-0.84.pth\")\n",
        "my_bert.cuda()\n",
        "regression = torch.load(\"/content/drive/My Drive/clinical-sts/models/dnn-regression-bert-base-uncased-0.84.pth\")\n",
        "\n",
        "predictions = get_predictions(my_bert, regression, test_dataloader)\n",
        "gs_scores = open(\"/content/drive/My Drive/clinical-sts/clinicalSTS2019.test.gs.sim.txt\", \"r\")\n",
        "actual_scores = [float(x.strip()) for x in gs_scores.readlines()]\n",
        "\n",
        "evaluate_predictions(predictions, actual_scores, test_dataloader, show_bad_predictions=True, prediction_difference=2.0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Dataset Pearson Correlation:  0.834843607409624\n",
            "BAD EXAMPLES\n",
            "actual  predicted     difference     SENTENCE\n",
            "0.00    2.08          2.08     the diagnosis and treatment plans were explained and the patient expressed understanding of the content. | patient and i processed some of the automatic thoughts, the moods associated with them, and the thought distortions accompanying the feelings.\n",
            "2.00    4.10          2.10     patient was agreeable to care plan and verbalized understanding. | she tolerated the session with no adverse reactions and verbalized understanding to the above plan of care.\n",
            "0.00    2.03          2.03     the patient tolerated the procedure well and was transferred to the recovery room in stable condition. | the patient was transferred to the patient appointment coordinator for an appointment to be scheduled within the timeframe advised.\n",
            "0.50    3.05          2.55     take a cellphone with you on the way to the emergency department. | reasons to return to the emergency department were discussed.\n",
            "0.50    2.52          2.02     negative for coughing up blood, coughing up mucus ( phlegm ) and wheezing. | negative for abdominal pain, blood in stool, constipation, diarrhea and vomiting.\n",
            "0.00    2.48          2.48     please contact location at phone number with any questions or concerns regarding this patient. | patient discharged ambulatory without further questions or concerns noted.\n",
            "1.50    3.57          2.07     i have reviewed the note and confirmed findings and recommendations. | she is calling for further evaluation and recommendations.\n",
            "2.00    4.04          2.04     gastrointestinal : negative for abdominal distention, abdominal pain, blood in stool, constipation, diarrhea, hematemesis, nausea and vomiting. | gastrointestinal : positive for abdominal distention, abdominal pain, nausea and vomiting.\n",
            "0.00    3.68          3.68     others you do with the help of your health care team. | thank you for choosing the name, aprn, c.n.p., d.n.p.. care team for your health care needs!\n",
            "0.00    2.18          2.18     the patient is discharging home with no new home health or equipment needs. | the patient notes and no new head and neck symptoms.\n",
            "0.50    3.84          3.34     gastrointestinal : negative for abdominal pain, diarrhea, nausea and vomiting. | negative for chest pain, palpitations and leg swelling.\n",
            "1.50    3.54          2.04     gastrointestinal : negative for abdominal distention, abdominal pain, blood in stool, constipation, diarrhea, nausea and vomiting. | gastrointestinal : positive for abdominal ( belly ) pain or cramping and heartburn.\n",
            "0.00    2.89          2.89     patient to call to schedule additional treatment sessions as needed otherwise patient dismissed from therapy. | patient tolerated session without adverse reactions to therapy.\n",
            "1.50    4.16          2.66     all questions regarding the planned procedure were answered. | all other questions were answered at the time of the visit.\n",
            "3.00    0.43          2.57     he was prepped and draped in the standard fashion. | the affected shoulder was prepared and draped with the usual sterile technique.\n",
            "4.50    2.42          2.08     it is a pleasure caring for this patient. | it was a pleasure to meet with her today.\n",
            "0.50    2.77          2.27     musculoskeletal : negative for back pain, neck pain, neck stiffness and extremity pain. | gastrointestinal : negative for abdominal pain, diarrhea and nausea.\n",
            "0.00    3.45          3.45     development : appropriate for age and growth are appropriate for age. | age - appropriate anticipatory guidance and injury prevention information was discussed.\n",
            "0.00    2.20          2.20     the client verbalized understanding and consented to the plan of care. | the patient consented to the possibility of blood transfusion.\n",
            "2.00    4.30          2.30     patient verbalized understanding through teachback and is in agreement with the healthcare plan. | the parent verbalized understanding of the plan and my contact information.\n",
            "2.50    0.23          2.27     the above has been discussed and reviewed in detail with the patient. | the family was advised that the content of this interview will be shared with the health care team.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSwuHVQ34Une",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "outputId": "60695c2a-988b-4c83-bf72-0a075954454a"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"/content/drive/My Drive/clinical-sts/bio-bert/\", output_hidden_states=True)\n",
        "test_dataloader = load_test_data(tokenizer=tokenizer, batch_size=1)\n",
        "\n",
        "my_bert = torch.load(\"/content/drive/My Drive/clinical-sts/models/dnn-new-bert-bio-bert-0.84.pth\")\n",
        "my_bert.cuda()\n",
        "regression = torch.load(\"/content/drive/My Drive/clinical-sts/models/dnn-new-regression-bio-bert-0.84.pth\")\n",
        "\n",
        "predictions = get_predictions(my_bert, regression, test_dataloader)\n",
        "gs_scores = open(\"/content/drive/My Drive/clinical-sts/clinicalSTS2019.test.gs.sim.txt\", \"r\")\n",
        "actual_scores = [float(x.strip()) for x in gs_scores.readlines()]\n",
        "\n",
        "evaluate_predictions(predictions, actual_scores, test_dataloader, show_bad_predictions=True, prediction_difference=2.0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Dataset Pearson Correlation:  0.8367026416860067\n",
            "BAD EXAMPLES\n",
            "actual  predicted     difference     SENTENCE\n",
            "0.00    2.33          2.33     the patient tolerated the procedure well and was transferred to the recovery room in stable condition. | the patient was transferred to the patient appointment coordinator for an appointment to be scheduled within the timeframe advised.\n",
            "0.50    3.23          2.73     take a cellphone with you on the way to the emergency department. | reasons to return to the emergency department were discussed.\n",
            "0.50    2.60          2.10     the patient tolerated the procedure well with no complications. | the patient has no other concerns at this time.\n",
            "2.50    0.26          2.24     patient seen and discussed with supervising consultant, dr. hand, who evaluated the patient and concurs with the assessment and plan. | the consent form was reviewed with the patient and her partner.\n",
            "0.00    3.13          3.13     please contact location at phone number with any questions or concerns regarding this patient. | patient discharged ambulatory without further questions or concerns noted.\n",
            "0.00    2.26          2.26     the patient was awakened from anesthesia and transported to the recovery room in stable condition. | the patient was instructed in wearing and caring for the orthosis.\n",
            "2.00    4.23          2.23     gastrointestinal : negative for abdominal distention, abdominal pain, blood in stool, constipation, diarrhea, hematemesis, nausea and vomiting. | gastrointestinal : positive for abdominal distention, abdominal pain, nausea and vomiting.\n",
            "0.00    3.64          3.64     others you do with the help of your health care team. | thank you for choosing the name, aprn, c.n.p., d.n.p.. care team for your health care needs!\n",
            "0.00    3.04          3.04     the patient is due for a provider visit at this time. | there are no other complaints at this time.\n",
            "0.00    2.52          2.52     the patient is discharging home with no new home health or equipment needs. | the patient notes and no new head and neck symptoms.\n",
            "3.00    5.58          2.58     he verbalized understanding and agrees to the plan. | mom verbalized understanding and agreement with the plan.\n",
            "0.50    3.21          2.71     gastrointestinal : negative for abdominal pain, diarrhea, nausea and vomiting. | negative for chest pain, palpitations and leg swelling.\n",
            "5.00    2.94          2.06     neurological : negative for numbness or shooting pain in hands, arms, legs, or feet. | negative for numbness or shooting pain in hands, arms, legs, or feet.\n",
            "2.50    4.66          2.16     ask to be connected to the following service : location hosp service. | ask to be connected to the following service : location surgery - name.\n",
            "0.50    2.83          2.33     with adequate anesthesia and akinesia the right eye was prepped and draped in the usual sterile fashion and the operating microscope was rotated into position. | preoperative antibiotics were administered and the patient was prepped and draped in a normal sterile fashion.\n",
            "0.50    2.52          2.02     patient will report >3+ ( somewhat better ) on the global rating of change in 12 sessions. | patient will demonstrate and / or verbalize understanding of home exercise program in 1 sessions.\n",
            "1.50    3.50          2.00     all questions regarding the planned procedure were answered. | all other questions were answered at the time of the visit.\n",
            "1.50    3.61          2.11     the patient was taken to the operating room where they underwent the above procedure. | the patient was then transferred to the operating room where anesthesia was administered by our anesthesia colleagues in accordance with our preoperative plan.\n",
            "0.00    2.66          2.66     development : appropriate for age and growth are appropriate for age. | age - appropriate anticipatory guidance and injury prevention information was discussed.\n",
            "0.00    3.16          3.16     the client verbalized understanding and consented to the plan of care. | the patient consented to the possibility of blood transfusion.\n",
            "1.00    3.26          2.26     oxycodone [ roxicodone ] 5 mg tablet 1 - 2 tablets by mouth every 6 hours as needed. | maxalt 10 mg tablet 1 tablet by mouth as directed by prescriber as needed.\n",
            "2.00    4.46          2.46     patient verbalized understanding through teachback and is in agreement with the healthcare plan. | the parent verbalized understanding of the plan and my contact information.\n",
            "2.50    0.40          2.10     the above has been discussed and reviewed in detail with the patient. | the family was advised that the content of this interview will be shared with the health care team.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOlhFKv4es5Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}