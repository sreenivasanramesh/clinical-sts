{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clinical_sts_train_part2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "duHGGbwVAhhL"
      },
      "source": [
        "!pip install nlp transformers texttable &> /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AArjDixQAvZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679e581c-9a73-4ec3-d518-27fe3153a896"
      },
      "source": [
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Optional\n",
        "from typing import List\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)  \n",
        "from texttable import Texttable\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "# import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset, IterableDataset\n",
        "from transformers import BertModel, BertTokenizer, AutoTokenizer, AutoModel, BertConfig, \\\n",
        "     AdamW, set_seed, AutoConfig, PreTrainedTokenizer, DataCollator, PreTrainedModel, PreTrainedTokenizer, DataCollator, PreTrainedModel\n",
        "\n",
        "set_seed(23)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3IyQ_MtPKlP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599e5b09-e0dd-48a4-b5f2-fcaf037cb456"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgQgo4I4wQZQ"
      },
      "source": [
        "\n",
        " \n",
        "## Processing Data, Defining Data Classes and Collator and other miscellaneous stuff\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7qFiKkjBtZ3"
      },
      "source": [
        "# Class to store data samples, text_a, text_b, score\n",
        "@dataclass\n",
        "class Example:\n",
        "    text_a: str\n",
        "    text_b: str\n",
        "    cui_embedding_a: list\n",
        "    cui_embedding_b: list\n",
        "    score: float\n",
        "\n",
        "\n",
        "# lowercase and add space around words, remove unnecessary spaces\n",
        "def pre_process(sentence, cased=False):\n",
        "    sentence = sentence.replace(\":\", \" : \").replace(\"/\", \" / \").replace(\"[\", \" [ \").replace(\"]\", \" ] \").replace(\"(\", \" ( \").replace(\")\", \" ) \").replace(\"\\\"\", \" \\\" \").replace(\"-\", \" - \").replace(\"?\", \" \").lstrip().rstrip()\n",
        "    if cased:\n",
        "      return re.sub(' +',' ', sentence)\n",
        "    return re.sub(' +',' ', sentence).lower()\n",
        "\n",
        "# def extract_cui_embedding(cui_string):\n",
        "#     return list(map(float, cui_string.split(\",\")))\n",
        "\n",
        "\n",
        "# returns test and train arrays as Example Objects\n",
        "# test train split is stratified and 80-20 split\n",
        "def get_data(cased=False):\n",
        "    train_data = \"/content/drive/My Drive/clinical-sts/augmented_train_with_cui_embeddings.tsv\"\n",
        "    df = pd.read_csv(train_data, sep=\"\\t\", names=[\"sentence_1\", \"sentence_2\", \"similarity_score\", \"label\", \"cuis_1\", \"cuis_2\", \"cui_embedding_1\", \"cui_embedding_2\"], encoding=\"utf-8\")\n",
        "    df[\"sentence_1\"] = df[\"sentence_1\"].apply(lambda sentence: pre_process(sentence, cased))\n",
        "    df[\"sentence_2\"] = df[\"sentence_2\"].apply(lambda sentence: pre_process(sentence, cased))\n",
        "    df[\"input_sample\"] = df[\"sentence_1\"] + \"<SEP>\" + df[\"sentence_2\"] + \"<SEP>\" + df[\"cui_embedding_1\"] + \"<SEP>\" + df[\"cui_embedding_2\"]\n",
        "\n",
        "    # print(df[\"input_sample\"])\n",
        "    # print(\"test\", df[\"cui_embedding_1\"])\n",
        "    # df[\"cui_embedding_1\"] = df[\"cui_embedding_1\"].apply(lambda embedding_str: extract_cui_embedding(embedding_str)) \n",
        "    # df[\"cui_embedding_2\"] = df[\"cui_embedding_2\"].apply(lambda embedding_str: extract_cui_embedding(embedding_str)) \n",
        "\n",
        "\n",
        "\n",
        "    ## stratified binned sampling\n",
        "    min_val = np.amin(df[\"similarity_score\"])\n",
        "    max_val = np.amax(df[\"similarity_score\"])\n",
        "    bins     = np.linspace(start=min_val, stop=max_val, num=10)\n",
        "    y_binned = np.digitize(df[\"similarity_score\"], bins, right=True)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df[\"input_sample\"],\n",
        "        df[\"similarity_score\"], \n",
        "        stratify=y_binned,\n",
        "        test_size=0.1,\n",
        "        random_state=23\n",
        "    )\n",
        "\n",
        "\n",
        "    for sample, similarity_score in zip(X_train, y_train):\n",
        "      try:\n",
        "        # print(\"heyyy\", sample.split(\"<SEP>\")[2].split(\",\"))\n",
        "        xx = list(map(float, sample.split(\"<SEP>\")[2].split(\",\")))\n",
        "        # print(\"yooo\", xx)\n",
        "      except:\n",
        "        print(\"ohnomy\", sample)\n",
        "\n",
        "    train_a_b = [Example(text_a=sample.split(\"<SEP>\")[0], \n",
        "                    text_b=sample.split(\"<SEP>\")[1],\n",
        "                    cui_embedding_a = list(map(float, sample.split(\"<SEP>\")[2].split(\",\"))),\n",
        "                    cui_embedding_b = list(map(float, sample.split(\"<SEP>\")[3].split(\",\"))),\n",
        "                    score=similarity_score) for sample, similarity_score in zip(X_train, y_train)]\n",
        "    train_b_a = [Example(text_a=sample.split(\"<SEP>\")[1], \n",
        "                    text_b=sample.split(\"<SEP>\")[0], \n",
        "                    cui_embedding_a = list(map(float, sample.split(\"<SEP>\")[3].split(\",\"))),\n",
        "                    cui_embedding_b = list(map(float, sample.split(\"<SEP>\")[2].split(\",\"))),\n",
        "                    score=similarity_score) for sample, similarity_score in zip(X_train, y_train)]\n",
        "    train = train_a_b + train_b_a\n",
        "\n",
        "    test_a_b = [Example(text_a=sample.split(\"<SEP>\")[0], \n",
        "                    text_b=sample.split(\"<SEP>\")[1], \n",
        "                    cui_embedding_a = list(map(float, sample.split(\"<SEP>\")[2].split(\",\"))),\n",
        "                    cui_embedding_b = list(map(float, sample.split(\"<SEP>\")[3].split(\",\"))),\n",
        "                    score=similarity_score) for sample, similarity_score in zip(X_test, y_test)]\n",
        "    test_b_a = [Example(text_a=sample.split(\"<SEP>\")[1], \n",
        "                    text_b=sample.split(\"<SEP>\")[0], \n",
        "                    cui_embedding_a = list(map(float, sample.split(\"<SEP>\")[3].split(\",\"))),\n",
        "                    cui_embedding_b = list(map(float, sample.split(\"<SEP>\")[2].split(\",\"))),\n",
        "                    score=similarity_score) for sample, similarity_score in zip(X_test, y_test)]\n",
        "    test = test_a_b + test_b_a\n",
        "\n",
        "    return train, test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# DYNAMIC PADDING AND UNIFORM LENGTH BATCHING - reduces wasted computation and makes it faster to run\n",
        "# CODE BORROWED FROM https://towardsdatascience.com/divide-hugging-face-transformers-training-time-by-2-or-more-21bf7129db9q-21bf7129db9e\n",
        "\n",
        "\n",
        "# We'll be creating a custome dataset using this first\n",
        "@dataclass\n",
        "class Features:\n",
        "    og_sample: Example\n",
        "    cui_embedding: List[float]\n",
        "    input_ids: List[int]\n",
        "    attention_mask: List[int]\n",
        "    score: float\n",
        "\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenizer, \n",
        "                 pad_to_max_length, \n",
        "                 max_len,\n",
        "                 examples: List[Example]):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.examples: List[Example] = examples\n",
        "        self.current = 0\n",
        "        self.pad_to_max_length = pad_to_max_length\n",
        "\n",
        "    # tokenize the sentences and return a Features object for each sentence \n",
        "    def encode(self, ex: Example) -> Features:\n",
        "        encode_dict = self.tokenizer.encode_plus(text=ex.text_a,\n",
        "                                                 text_pair=ex.text_b,\n",
        "                                                 add_special_tokens=True,\n",
        "                                                 max_length=self.max_len,\n",
        "                                                 pad_to_max_length=self.pad_to_max_length,\n",
        "                                                 return_token_type_ids=False,\n",
        "                                                 return_attention_mask=True,\n",
        "                                                 return_overflowing_tokens=False,\n",
        "                                                 return_special_tokens_mask=False,\n",
        "                                                 truncation=True,\n",
        "                                                 )\n",
        "        return Features(og_sample=ex,\n",
        "                        cui_embedding=ex.cui_embedding_a+ex.cui_embedding_b,\n",
        "                        input_ids=encode_dict[\"input_ids\"],\n",
        "                        attention_mask=encode_dict[\"attention_mask\"],\n",
        "                        score=ex.score)\n",
        "\n",
        "    def __getitem__(self, idx) -> Features:\n",
        "        return self.encode(ex=self.examples[idx])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "\n",
        "def pad_seq(seq: List[int], max_batch_len: int, pad_value: int) -> List[int]:\n",
        "    return seq + (max_batch_len - len(seq)) * [pad_value]\n",
        "\n",
        "\n",
        "# Smart Collator is used to create batches which are dynamically padded with uniform length \n",
        "@dataclass\n",
        "class SmartCollator:  # (DataCollator):\n",
        "    pad_token_id: int\n",
        "\n",
        "    def collate_batch(self, batch: List[Features]) -> Dict[str, torch.Tensor]:\n",
        "        batch_og_sample = list()\n",
        "        batch_cui_embedding = list()\n",
        "        batch_inputs = list()\n",
        "        batch_attention_masks = list()\n",
        "        labels = list()\n",
        "        max_size = max([len(ex.input_ids) for ex in batch])\n",
        "        for item in batch:\n",
        "            batch_inputs += [pad_seq(item.input_ids, max_size, self.pad_token_id)]\n",
        "            batch_attention_masks += [pad_seq(item.attention_mask, max_size, 0)]\n",
        "            labels.append(item.score)\n",
        "            batch_og_sample.append(item)\n",
        "            batch_cui_embedding.append(np.array(item.cui_embedding))\n",
        "\n",
        "        return {\"input_ids\": torch.tensor(batch_inputs, dtype=torch.long),\n",
        "                \"attention_mask\": torch.tensor(batch_attention_masks, dtype=torch.long),\n",
        "                \"score\": torch.tensor(labels, dtype=torch.float),\n",
        "                \"og_sample\": batch_og_sample,\n",
        "                \"cui_embedding\": torch.tensor(batch_cui_embedding, dtype=torch.float)\n",
        "                }\n",
        "                \n",
        "def collate_wrapper(data):\n",
        "    collator = SmartCollator(pad_token_id=tokenizer.pad_token_id)\n",
        "    return collator.collate_batch(data)\n",
        "\n",
        "\n",
        "# USE THIS FUNCTION TO LOAD TEST AND TRAIN DATA AND ITERATE THROUGH THEM\n",
        "def load_data(tokenizer, batch_size, cased=False):\n",
        "    # Get train and test Data Examples\n",
        "    train, test = get_data(cased)\n",
        "\n",
        "\n",
        "    # Now tokenize the words and convert them to token IDs\n",
        "    max_sequence_len = 256\n",
        "    train_set = TextDataset(tokenizer=tokenizer,\n",
        "                            max_len=max_sequence_len,\n",
        "                            examples=train,\n",
        "                            pad_to_max_length=False)\n",
        "\n",
        "    test_set = TextDataset(tokenizer=tokenizer,\n",
        "                            max_len=max_sequence_len,\n",
        "                            examples=test,\n",
        "                            pad_to_max_length=False)\n",
        "\n",
        "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_wrapper,\n",
        "              pin_memory=False, drop_last=False, timeout=0,\n",
        "              worker_init_fn=None)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_wrapper,\n",
        "              pin_memory=False, drop_last=False, timeout=0,\n",
        "              worker_init_fn=None)\n",
        "    \n",
        "    return train_dataloader, test_dataloader"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJMdJI0Ewkkc"
      },
      "source": [
        "##**Define the Training Loop for fine-tuning the Model.**  \n",
        "We also have some miscellaneous functions to evaluate our model on the dev-set.  \n",
        "\n",
        "  \n",
        "    \n",
        "The model is as shown below. We have different learning rates for the bert and LR layer. Note that we take the hidden layer output from BERT and not the CLS embedding. The CLS embedding does not generate any meaningful sentence embedding and BERT was specifically trained for the NSP task. As such, using the CLS embedding directly leads to worse results. We found that using the penultimate hidden layers gave us best results for this task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ALszvbWE5Zc"
      },
      "source": [
        "# Let's define the training loop and model\n",
        "\n",
        "def get_bert_output(my_bert, input_ids, attention_mask):    \n",
        "    outputs = my_bert(input_ids, attention_mask=attention_mask)\n",
        "    hidden_states = outputs[2]\n",
        "    sent_embedding = hidden_states[11][:, 0:1, :].squeeze(1).cuda()\n",
        "    return sent_embedding\n",
        "\n",
        "\n",
        "# class linearRegression(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(linearRegression, self).__init__()\n",
        "#         self.linear = nn.Linear(868, 1)\n",
        "#     def forward(self, x):\n",
        "#         out = self.linear(x)\n",
        "#         return out\n",
        "\n",
        "\n",
        "class linearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(linearRegression, self).__init__()\n",
        "        self.linear_1 = nn.Sequential(\n",
        "                            nn.Linear(868, 256),\n",
        "                            nn.ReLU())\n",
        "        self.linear_2 = nn.Linear(256, 1)\n",
        "    def forward(self, x):\n",
        "        out = self.linear_1(x)\n",
        "        out = self.linear_2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# class CNN(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(CNN, self).__init__()\n",
        "\n",
        "#         self.layer12 = nn.Sequential(\n",
        "#             nn.Conv1d(in_channels=868, out_channels=1024, kernel_size=4),\n",
        "#             nn.BatchNorm1d(1024),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(kernel_size=4, stride=2),\n",
        "#             nn.Dropout(0.2),\n",
        "#             nn.Conv1d(in_channels=1024, out_channels=256, kernel_size=1),\n",
        "#             nn.BatchNorm1d(256),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(kernel_size=1, stride=1),\n",
        "#             nn.Dropout(0.2)\n",
        "#         )\n",
        "\n",
        "#         self.fc1 = nn.Sequential(\n",
        "#             nn.Linear(256, 64),\n",
        "#             nn.BatchNorm1d(64),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Dropout(0.2)\n",
        "#         )\n",
        "#         self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out = self.layer12(x)\n",
        "#         out = self.fc1(out)\n",
        "#         out = self.fc2(out)\n",
        "#         return out\n",
        "    \n",
        "\n",
        "def run_new_method(my_bert, optimizer, regression_head, regression_optimizer, train_dataloader, test_dataloader, epochs=10, freeze_layers=False):\n",
        "    old_test_loss = float('inf')\n",
        "\n",
        "    # freeze_layers = \"0,1,2,3,4\"\n",
        "    if freeze_layers:\n",
        "        freeze_layers = \"0,1,2,3,4,5\"\n",
        "        layer_indexes = [int(x) for x in freeze_layers.split(\",\")]\n",
        "        for layer_idx in layer_indexes:\n",
        "            for param in list(my_bert.encoder.layer[layer_idx].parameters()):\n",
        "                param.requires_grad = False\n",
        "            print (\"Froze Layer: \", layer_idx)\n",
        "\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "        total_loss = 0\n",
        "        batch_count = 0\n",
        "        # put model in train mode\n",
        "        my_bert.train()\n",
        "        regression_head.train()\n",
        "        for step_num, batch_data in enumerate(train_dataloader):\n",
        "            input_ids = batch_data[\"input_ids\"].to(device)\n",
        "            attention_mask = batch_data[\"attention_mask\"].to(device)\n",
        "            score = batch_data[\"score\"].to(device)\n",
        "            score = score.unsqueeze(1)\n",
        "            cui_embedding = batch_data[\"cui_embedding\"].to(device)\n",
        "\n",
        "            my_bert_optimizer.zero_grad()\n",
        "            regression_optimizer.zero_grad()\n",
        "            bert_embedding = get_bert_output(my_bert, input_ids, attention_mask)\n",
        "\n",
        "            bert_cui_embedding = torch.cat((bert_embedding, cui_embedding), dim=1)\n",
        "            # print(bert_cui_embedding)\n",
        "            predicted_score = regression_head(bert_cui_embedding)\n",
        "\n",
        "            loss_func = nn.MSELoss()\n",
        "            batch_loss = loss_func(predicted_score, score)\n",
        "\n",
        "            \n",
        "            batch_loss.backward()\n",
        "            my_bert_optimizer.step()\n",
        "            regression_optimizer.step()\n",
        "            total_loss += batch_loss.item()\n",
        "            batch_count += 1\n",
        "            train_loss = total_loss/batch_count\n",
        "        print(\"Epoch: {} Train Loss:{}\".format(epoch_num, train_loss))\n",
        "\n",
        "        # put model in test mode\n",
        "        my_bert.eval()\n",
        "        regression_head.eval()\n",
        "        test_loss = 0\n",
        "        test_batch_count = 0\n",
        "        with torch.no_grad():\n",
        "            for step_num, batch_data in enumerate(test_dataloader):\n",
        "                input_ids = batch_data[\"input_ids\"].to(device)\n",
        "                attention_mask = batch_data[\"attention_mask\"].to(device)\n",
        "                score = batch_data[\"score\"].to(device)\n",
        "                score = score.unsqueeze(1)\n",
        "                cui_embedding = batch_data[\"cui_embedding\"].to(device)\n",
        "\n",
        "                bert_embedding = get_bert_output(my_bert, input_ids, attention_mask)\n",
        "                bert_cui_embedding = torch.cat((bert_embedding, cui_embedding), dim=1)\n",
        "                # print(bert_cui_embedding)\n",
        "                predicted_score = regression_head(bert_cui_embedding)\n",
        "                #predicted_score = regression_head(bert_embedding)\n",
        "\n",
        "                loss_func = nn.MSELoss()\n",
        "                batch_loss = loss_func(predicted_score, score)\n",
        "                test_loss += batch_loss.item()\n",
        "                test_batch_count += 1\n",
        "        curr_test_loss = test_loss/test_batch_count\n",
        "        print(\"Epoch: {} Test Loss:{}\\n\".format(epoch_num, curr_test_loss))\n",
        "        if curr_test_loss < 0.60 or train_loss < 0.25:\n",
        "            print(\"yay, exit\")\n",
        "            break\n",
        "        # curr_test_loss = test_loss/test_batch_count\n",
        "        # if curr_test_loss-old_test_loss >= 0.03 or curr_test_loss<0.61:\n",
        "        #     print(\"new test loss is greater; breaking\")\n",
        "        #     break\n",
        "        # old_test_loss = curr_test_loss\n",
        "    return my_bert, regression_head\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "    Method to evaluate and calculate pcc on dev/test dataset, and show terrible predictions\n",
        "'''\n",
        "def evaluate_model(model, regression_head, test_dataloader, show_bad_predictions=True, prediction_difference=2.0):\n",
        "\n",
        "    actual = list()\n",
        "    predicted = list()\n",
        "    og_data = list()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_batch_count = 0\n",
        "        test_loss =0\n",
        "        for step_num, batch_data in enumerate(test_dataloader):\n",
        "            input_ids = batch_data[\"input_ids\"].to(device)\n",
        "            attention_mask = batch_data[\"attention_mask\"].to(device)\n",
        "            score = batch_data[\"score\"].to(device)\n",
        "            score = score.unsqueeze(1)\n",
        "\n",
        "            cui_embedding = batch_data[\"cui_embedding\"].to(device)\n",
        "            bert_embedding = get_bert_output(model, input_ids, attention_mask)\n",
        "            bert_cui_embedding = torch.cat((bert_embedding, cui_embedding), dim=1)\n",
        "            predicted_score = regression_head(bert_cui_embedding)\n",
        "\n",
        "            actual.extend(score.tolist())\n",
        "            predicted.extend(predicted_score.tolist())\n",
        "            original_samples = batch_data[\"og_sample\"]\n",
        "            og_data.extend(original_samples)\n",
        "\n",
        "    # show bad predictions in a table\n",
        "    table = Texttable()\n",
        "    table.add_row([\"Actual\", \"Predicted\", \"Difference\", \"Text Sample\"])\n",
        "\n",
        "    for act, pre, og_data in zip(actual, predicted, og_data):\n",
        "        if abs(pre[0]-act[0]) > prediction_difference:\n",
        "            og = og_data.og_sample.text_a + \"    |||    \" + og_data.og_sample.text_b\n",
        "            print(\"{:.2f}    {:.2f}          {:.2f}     {}\".format(act[0], pre[0], abs(pre[0]-act[0]), og))\n",
        "\n",
        "    print('\\n\\n\\n')\n",
        "    actual = [item[0] for item in actual]\n",
        "    predicted = [item[0] for item in predicted]\n",
        "\n",
        "    correlation, p_value = pearsonr(actual, predicted)\n",
        "    print(correlation)\n",
        "\n",
        "    d = {\"a\": actual, \"p\": predicted}\n",
        "    dx = pd.DataFrame(d)\n",
        "    dx.plot.hist(bins=20, alpha=0.25)\n",
        "    return correlation\n",
        "\n",
        "\n",
        "def get_optimizer_params(model):\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    opt_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "    return opt_parameters\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9u2XL6HB6AZ"
      },
      "source": [
        "## **Select the base model to fine tune, and pass it to the train loop**\n",
        "We then evaluate the PCC on the dev set.  \n",
        "Note: Only bad examples and scores are printed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "6tEoOK4FEwx6",
        "outputId": "dd324414-f259-454d-9cf8-1a896493e0dc"
      },
      "source": [
        "MODEL = \"bert-base-uncased\"\n",
        "my_bert = BertModel.from_pretrained(MODEL, output_hidden_states=True)\n",
        "my_bert.cuda()\n",
        "\n",
        "regression_head = linearRegression().cuda()\n",
        "linear_regression_optimizer = torch.optim.Adam(regression_head.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL, output_hidden_states=True)\n",
        "train_dataloader, test_dataloader = load_data(tokenizer=tokenizer, batch_size=8)\n",
        "bert_config = BertConfig.from_pretrained(MODEL, output_hidden_states=True)\n",
        "my_bert_optimizer = AdamW(get_optimizer_params(my_bert), lr=1e-5)\n",
        "updated_model, regression_head = run_new_method(my_bert=my_bert, optimizer=my_bert_optimizer, # optimizer\n",
        "                                                regression_head=regression_head, \n",
        "                                                regression_optimizer=linear_regression_optimizer,\n",
        "                                                train_dataloader=train_dataloader,\n",
        "                                                test_dataloader=test_dataloader,\n",
        "                                                epochs=3)\n",
        "\n",
        "pcc = evaluate_model(updated_model, regression_head, test_dataloader)\n",
        "model_loc = \"/content/drive/My Drive/clinical-sts/models/dnn-bert-{}-{:.2f}.pth\".format(MODEL, pcc)\n",
        "regression_loc = \"/content/drive/My Drive/clinical-sts/models/dnn-regression-{}-{:.2f}.pth\".format(MODEL, pcc)\n",
        "torch.save(updated_model, model_loc)\n",
        "torch.save(regression_head, regression_loc)\n",
        "print(\"Saved at:\\n'{}'\\n'{}'\".format(model_loc, regression_loc))\n",
        "\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train Loss:1.027175054786969\n",
            "Epoch: 0 Test Loss:0.6413795124874058\n",
            "\n",
            "Epoch: 1 Train Loss:0.3778907054320563\n",
            "Epoch: 1 Test Loss:0.6857050691383431\n",
            "\n",
            "Epoch: 2 Train Loss:0.2659784017575291\n",
            "Epoch: 2 Test Loss:0.6877985835434443\n",
            "\n",
            "2.00    4.23          2.23     discussed diagnosis and treatment plan; patient expressed understanding of the content.    |||    they verbalized agreement and understanding of the plan and contact information.\n",
            "0.00    2.27          2.27     i discussed with the patient the findings of the physical exam.    |||    i have confirmed with the organization system that i have counseled the patient.\n",
            "1.50    3.55          2.05     the patient indicated they are not missing work, are not experiencing reduced productivity at work, are having no decline in their ability to complete daily activities.    |||    the patient indicated they are having decline in their ability to complete daily activities ( score of 5 / 10, where 0=no effect ) .\n",
            "1.00    4.59          3.59     the patient is awake, alert, and oriented times three.    |||    patient is appreciative, understands and is in agreement with plan of care.\n",
            "3.25    1.16          2.09     discussed the risks, the goals, the alternatives, advance directives, and the necessity of other members of the health care team who would be participating in the procedures with the patient.    |||    i reviewed pertinent records, examined the patient and discussed the plan of care with rcu team at the bedside.\n",
            "2.75    0.53          2.22     the patient has had a chance to have their questions about this procedure answered and wishes to proceed.    |||    the patient was instructed to contact me with regard to any questions pertaining to the injection and to inform me of the results in a period of approximately two weeks.\n",
            "1.50    4.16          2.66     , family educational needs - family assessed : ready to learn, no apparent learning barriers.    |||    patient education : ready to learn, no apparent learning barriers were identified; learning preferences include listening.\n",
            "5.00    2.66          2.34     please let me know how i can help.    |||    please let us know if there is anything else we can do for you.\n",
            "1.50    3.67          2.17     i have reviewed the physician assistant and nursing documentation, studies, and consultations and agree with the findings documented on the written ed record.    |||    i discussed the rehabilitation plans with the patient and they voiced understanding and agreement with the plans.\n",
            "1.50    3.92          2.42     contact your health care provider if you have any further questions or concerns.    |||    contact your health care provider right away if you are having lasting feelings of depression or anxiety.\n",
            "2.00    4.40          2.40     explained diagnosis and treatment plan; patient expressed understanding of the content, patient was given a copy of this note    |||    explained diagnosis and treatment plan; patient / child / caretaker expressed understanding of the content.`e`\n",
            "3.25    1.23          2.02     patient has no smoking history, patient denies alcohol use, drug use, lives in long term care facility.    |||    patient currently uses tobacco, smokes cigarettes, daily, with number per day : 10, patient denies alcohol use, drug use.\n",
            "0.50    2.74          2.24     negative gastrointestinal review of systems, historian denies abdominal pain, diarrhea, nausea, vomiting.    |||    negative neurologic review of systems, historian denies confusion, dizziness, headache, mental status changes.\n",
            "2.00    4.18          2.18     they verbalized agreement and understanding of the plan and contact information.    |||    discussed diagnosis and treatment plan; patient expressed understanding of the content.\n",
            "0.00    2.06          2.06     i have confirmed with the organization system that i have counseled the patient.    |||    i discussed with the patient the findings of the physical exam.\n",
            "1.00    4.30          3.30     patient is appreciative, understands and is in agreement with plan of care.    |||    the patient is awake, alert, and oriented times three.\n",
            "3.00    0.62          2.38     the impression and treatment plan were explained in detail to the patient / family who expressed understanding of the content.    |||    after explaining the procedure to the patient / caregiver, ear lavage of both ears was attempted .\n",
            "1.50    4.28          2.78     patient education : ready to learn, no apparent learning barriers were identified; learning preferences include listening.    |||    , family educational needs - family assessed : ready to learn, no apparent learning barriers.\n",
            "5.00    2.87          2.13     please let us know if there is anything else we can do for you.    |||    please let me know how i can help.\n",
            "1.50    3.79          2.29     i discussed the rehabilitation plans with the patient and they voiced understanding and agreement with the plans.    |||    i have reviewed the physician assistant and nursing documentation, studies, and consultations and agree with the findings documented on the written ed record.\n",
            "1.50    3.94          2.44     contact your health care provider right away if you are having lasting feelings of depression or anxiety.    |||    contact your health care provider if you have any further questions or concerns.\n",
            "2.00    4.43          2.43     explained diagnosis and treatment plan; patient / child / caretaker expressed understanding of the content.`e`    |||    explained diagnosis and treatment plan; patient expressed understanding of the content, patient was given a copy of this note\n",
            "0.50    2.50          2.00     negative neurologic review of systems, historian denies confusion, dizziness, headache, mental status changes.    |||    negative gastrointestinal review of systems, historian denies abdominal pain, diarrhea, nausea, vomiting.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0.8307496627470554\n",
            "Saved at:\n",
            "'/content/drive/My Drive/clinical-sts/models/dnn-bert-bert-base-uncased-0.83.pth'\n",
            "'/content/drive/My Drive/clinical-sts/models/dnn-regression-bert-base-uncased-0.83.pth'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ1x2B-YZU0s"
      },
      "source": [
        "LALALA\n",
        "**bold text****bold text**\n",
        "```\n",
        "`# This is formatted as code`\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "4QgGNLUOXK59",
        "outputId": "bc0a4977-5c0b-4c56-ad24-f7a7cd2f298e"
      },
      "source": [
        "MODEL = \"/content/drive/My Drive/clinical-sts/bio-bert/\"\n",
        "my_bert = BertModel.from_pretrained(MODEL, output_hidden_states=True)\n",
        "my_bert.cuda()\n",
        "\n",
        "regression_head = linearRegression().cuda()\n",
        "linear_regression_optimizer = torch.optim.Adam(regression_head.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL, output_hidden_states=True)\n",
        "train_dataloader, test_dataloader = load_data(tokenizer=tokenizer, batch_size=8)\n",
        "bert_config = BertConfig.from_pretrained(MODEL, output_hidden_states=True)\n",
        "my_bert_optimizer = AdamW(get_optimizer_params(my_bert), lr=1e-5)\n",
        "updated_model, regression_head = run_new_method(my_bert=my_bert, optimizer=my_bert_optimizer, # optimizer\n",
        "                                                regression_head=regression_head, \n",
        "                                                regression_optimizer=linear_regression_optimizer,\n",
        "                                                train_dataloader=train_dataloader,\n",
        "                                                test_dataloader=test_dataloader,\n",
        "                                                epochs=5)\n",
        "\n",
        "pcc = evaluate_model(updated_model, regression_head, test_dataloader)\n",
        "model_name = \"bio-bert\"\n",
        "model_loc = \"/content/drive/My Drive/clinical-sts/models/new-bert-{}-{:.2f}.pth\".format(model_name, pcc)\n",
        "regression_loc = \"/content/drive/My Drive/clinical-sts/models/new-regression-{}-{:.2f}.pth\".format(model_name, pcc)\n",
        "torch.save(updated_model, model_loc)\n",
        "torch.save(regression_head, regression_loc)\n",
        "print(\"Saved at:\\n'{}'\\n'{}'\".format(model_loc, regression_loc))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train Loss:0.9167840513450805\n",
            "Epoch: 0 Test Loss:0.6192541285639718\n",
            "\n",
            "Epoch: 1 Train Loss:0.3527099231999087\n",
            "Epoch: 1 Test Loss:0.6795851620180267\n",
            "\n",
            "Epoch: 2 Train Loss:0.22434371529567626\n",
            "Epoch: 2 Test Loss:0.7025330886244774\n",
            "\n",
            "yay, exit\n",
            "2.00    4.43          2.43     discussed diagnosis and treatment plan; patient expressed understanding of the content.    |||    they verbalized agreement and understanding of the plan and contact information.\n",
            "1.50    3.51          2.01     i have reviewed the physician assistant and nursing documentation, studies, and consultations and agree with the findings documented on the written ed record.    |||    i discussed the rehabilitation plans with the patient and they voiced understanding and agreement with the plans.\n",
            "1.50    3.90          2.40     the patient indicated they are not missing work, are not experiencing reduced productivity at work, are having no decline in their ability to complete daily activities.    |||    the patient indicated they are having decline in their ability to complete daily activities ( score of 5 / 10, where 0=no effect ) .\n",
            "1.00    4.08          3.08     the patient is awake, alert, and oriented times three.    |||    patient is appreciative, understands and is in agreement with plan of care.\n",
            "1.50    3.82          2.32     , family educational needs - family assessed : ready to learn, no apparent learning barriers.    |||    patient education : ready to learn, no apparent learning barriers were identified; learning preferences include listening.\n",
            "2.00    4.72          2.72     they verbalized agreement and understanding of the plan and contact information.    |||    discussed diagnosis and treatment plan; patient expressed understanding of the content.\n",
            "1.50    3.89          2.39     the patient indicated they are having decline in their ability to complete daily activities ( score of 5 / 10, where 0=no effect ) .    |||    the patient indicated they are not missing work, are not experiencing reduced productivity at work, are having no decline in their ability to complete daily activities.\n",
            "1.00    4.26          3.26     patient is appreciative, understands and is in agreement with plan of care.    |||    the patient is awake, alert, and oriented times three.\n",
            "4.00    1.85          2.15     thank you for choosing the name, m.d.. care team for your health care needs!    |||    thank you for contacting the xxx anticoagulation clinic.\n",
            "1.50    3.69          2.19     patient education : ready to learn, no apparent learning barriers were identified; learning preferences include listening.    |||    , family educational needs - family assessed : ready to learn, no apparent learning barriers.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0.8423632162512584\n",
            "Saved at:\n",
            "'/content/drive/My Drive/clinical-sts/models/new-bert-bio-bert-0.84.pth'\n",
            "'/content/drive/My Drive/clinical-sts/models/new-regression-bio-bert-0.84.pth'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZGZYiBLVoYz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}