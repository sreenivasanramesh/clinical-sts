{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train-on-partial-data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "duHGGbwVAhhL"
      },
      "source": [
        "!pip install nlp transformers texttable &> /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AArjDixQAvZo",
        "outputId": "bb299704-11be-4110-9211-dad038c51413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, Optional\n",
        "from typing import List\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)  \n",
        "from texttable import Texttable\n",
        "\n",
        "from scipy.stats import pearsonr, entropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset, IterableDataset\n",
        "from transformers import BertModel, BertTokenizer, AutoTokenizer, AutoModel, BertConfig, \\\n",
        "     AdamW, set_seed, AutoConfig, PreTrainedTokenizer, DataCollator, PreTrainedModel, PreTrainedTokenizer, DataCollator, PreTrainedModel\n",
        "\n",
        "set_seed(23)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3IyQ_MtPKlP",
        "outputId": "17b732a9-71a1-4293-d944-e92285945f3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgQgo4I4wQZQ"
      },
      "source": [
        "\n",
        " \n",
        "## Processing Data, Defining Data Classes and Collator and other miscellaneous stuff\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7qFiKkjBtZ3"
      },
      "source": [
        "# Class to store data samples, text_a, text_b, score\n",
        "@dataclass\n",
        "class Example:\n",
        "    text_a: str\n",
        "    text_b: str\n",
        "    score: float\n",
        "\n",
        "\n",
        "# lowercase and add space around words, remove unnecessary spaces\n",
        "def pre_process(sentence, cased=False):\n",
        "    sentence = sentence.replace(\":\", \" : \").replace(\"/\", \" / \").replace(\"[\", \" [ \").replace(\"]\", \" ] \").replace(\"(\", \" ( \").replace(\")\", \" ) \").replace(\"\\\"\", \" \\\" \").replace(\"-\", \" - \").replace(\"?\", \" \").lstrip().rstrip()\n",
        "    if cased:\n",
        "      return re.sub(' +',' ', sentence)\n",
        "    return re.sub(' +',' ', sentence).lower()\n",
        "\n",
        "\n",
        "# returns test and train arrays as Example Objects\n",
        "# test train split is stratified and 80-20 split\n",
        "def get_data(cased=False, sent_type=None):\n",
        "    train_data = \"/content/drive/My Drive/clinical-sts/augmented_train.tsv\"\n",
        "\n",
        "    df = pd.read_csv(train_data, sep=\"\\t\", names=[\"sentence_1\", \"sentence_2\", \"similarity_score\", \"label\"], encoding=\"utf-8\")\n",
        "    if sent_type == \"CLINICAL\":\n",
        "        df = df[df[\"label\"]==\"CLINICAL\"]\n",
        "    elif sent_type == \"MEDICAL\":\n",
        "        df = df[df[\"label\"]==\"MEDICAL\"]\n",
        "\n",
        "    df[\"sentence_1\"] = df[\"sentence_1\"].apply(lambda sentence: pre_process(sentence, cased))\n",
        "    df[\"sentence_2\"] = df[\"sentence_2\"].apply(lambda sentence: pre_process(sentence, cased))\n",
        "    df[\"input_sample\"] = df[\"sentence_1\"] + \"<SEP>\" + df[\"sentence_2\"]\n",
        "\n",
        "    ## stratified binned sampling\n",
        "    min_val = np.amin(df[\"similarity_score\"])\n",
        "    max_val = np.amax(df[\"similarity_score\"])\n",
        "    bins     = np.linspace(start=min_val, stop=max_val, num=10)\n",
        "    y_binned = np.digitize(df[\"similarity_score\"], bins, right=True)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df[\"input_sample\"], \n",
        "        df[\"similarity_score\"], \n",
        "        stratify=y_binned,\n",
        "        test_size=0.2,\n",
        "        random_state=23\n",
        "    )\n",
        "\n",
        "    train_a_b = [Example(text_a=sample.split(\"<SEP>\")[0], \n",
        "                    text_b=sample.split(\"<SEP>\")[1], \n",
        "                    score=similarity_score) for sample, similarity_score in zip(X_train, y_train)]\n",
        "    train_b_a = [Example(text_a=sample.split(\"<SEP>\")[1], \n",
        "                    text_b=sample.split(\"<SEP>\")[0], \n",
        "                    score=similarity_score) for sample, similarity_score in zip(X_train, y_train)]\n",
        "    train = train_a_b + train_b_a\n",
        "\n",
        "    test_a_b = [Example(text_a=sample.split(\"<SEP>\")[0], \n",
        "                    text_b=sample.split(\"<SEP>\")[1], \n",
        "                    score=similarity_score) for sample, similarity_score in zip(X_test, y_test)]\n",
        "    test_b_a = [Example(text_a=sample.split(\"<SEP>\")[1], \n",
        "                    text_b=sample.split(\"<SEP>\")[0], \n",
        "                    score=similarity_score) for sample, similarity_score in zip(X_test, y_test)]\n",
        "    test = test_a_b + test_b_a\n",
        "\n",
        "    return train, test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# DYNAMIC PADDING AND UNIFORM LENGTH BATCHING - reduces wasted computation and makes it faster to run\n",
        "# CODE BORROWED FROM https://towardsdatascience.com/divide-hugging-face-transformers-training-time-by-2-or-more-21bf7129db9q-21bf7129db9e\n",
        "\n",
        "\n",
        "# We'll be creating a custome dataset using this first\n",
        "@dataclass\n",
        "class Features:\n",
        "    og_sample: Example\n",
        "    input_ids: List[int]\n",
        "    attention_mask: List[int]\n",
        "    score: float\n",
        "\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenizer, \n",
        "                 pad_to_max_length, \n",
        "                 max_len,\n",
        "                 examples: List[Example]):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.examples: List[Example] = examples\n",
        "        self.current = 0\n",
        "        self.pad_to_max_length = pad_to_max_length\n",
        "\n",
        "    # tokenize the sentences and return a Features object for each sentence \n",
        "    def encode(self, ex: Example) -> Features:\n",
        "        encode_dict = self.tokenizer.encode_plus(text=ex.text_a,\n",
        "                                                 text_pair=ex.text_b,\n",
        "                                                 add_special_tokens=True,\n",
        "                                                 max_length=self.max_len,\n",
        "                                                 pad_to_max_length=self.pad_to_max_length,\n",
        "                                                 return_token_type_ids=False,\n",
        "                                                 return_attention_mask=True,\n",
        "                                                 return_overflowing_tokens=False,\n",
        "                                                 return_special_tokens_mask=False,\n",
        "                                                 truncation=True,\n",
        "                                                 )\n",
        "        return Features(og_sample=ex,\n",
        "                        input_ids=encode_dict[\"input_ids\"],\n",
        "                        attention_mask=encode_dict[\"attention_mask\"],\n",
        "                        score=ex.score)\n",
        "\n",
        "    def __getitem__(self, idx) -> Features:\n",
        "        return self.encode(ex=self.examples[idx])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "\n",
        "def pad_seq(seq: List[int], max_batch_len: int, pad_value: int) -> List[int]:\n",
        "    return seq + (max_batch_len - len(seq)) * [pad_value]\n",
        "\n",
        "\n",
        "# Smart Collator is used to create batches which are dynamically padded with uniform length \n",
        "@dataclass\n",
        "class SmartCollator:  # (DataCollator):\n",
        "    pad_token_id: int\n",
        "\n",
        "    def collate_batch(self, batch: List[Features]) -> Dict[str, torch.Tensor]:\n",
        "        batch_og_sample = list()\n",
        "        batch_inputs = list()\n",
        "        batch_attention_masks = list()\n",
        "        labels = list()\n",
        "        max_size = max([len(ex.input_ids) for ex in batch])\n",
        "        for item in batch:\n",
        "            batch_inputs += [pad_seq(item.input_ids, max_size, self.pad_token_id)]\n",
        "            batch_attention_masks += [pad_seq(item.attention_mask, max_size, 0)]\n",
        "            labels.append(item.score)\n",
        "            batch_og_sample.append(item)\n",
        "\n",
        "        return {\"input_ids\": torch.tensor(batch_inputs, dtype=torch.long),\n",
        "                \"attention_mask\": torch.tensor(batch_attention_masks, dtype=torch.long),\n",
        "                \"score\": torch.tensor(labels, dtype=torch.float),\n",
        "                \"og_sample\": batch_og_sample\n",
        "                }\n",
        "                \n",
        "def collate_wrapper(data):\n",
        "    collator = SmartCollator(pad_token_id=tokenizer.pad_token_id)\n",
        "    return collator.collate_batch(data)\n",
        "\n",
        "\n",
        "# USE THIS FUNCTION TO LOAD TEST AND TRAIN DATA AND ITERATE THROUGH THEM\n",
        "def load_data(tokenizer, batch_size, cased=False, sent_type=None):\n",
        "    # Get train and test Data Examples\n",
        "    train, test = get_data(cased, sent_type)\n",
        "\n",
        "\n",
        "    # Now tokenize the words and convert them to token IDs\n",
        "    max_sequence_len = 128\n",
        "    train_set = TextDataset(tokenizer=tokenizer,\n",
        "                            max_len=max_sequence_len,\n",
        "                            examples=train,\n",
        "                            pad_to_max_length=False)\n",
        "\n",
        "    test_set = TextDataset(tokenizer=tokenizer,\n",
        "                            max_len=max_sequence_len,\n",
        "                            examples=test,\n",
        "                            pad_to_max_length=False)\n",
        "\n",
        "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_wrapper,\n",
        "              pin_memory=False, drop_last=False, timeout=0,\n",
        "              worker_init_fn=None)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn=collate_wrapper,\n",
        "              pin_memory=False, drop_last=False, timeout=0,\n",
        "              worker_init_fn=None)\n",
        "    \n",
        "    return train_dataloader, test_dataloader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJMdJI0Ewkkc"
      },
      "source": [
        "##**Define the Training Loop for fine-tuning the Model.**  \n",
        "We also have some miscellaneous functions to evaluate our model on the dev-set.  \n",
        "\n",
        "  \n",
        "    \n",
        "The model is as shown below. We have different learning rates for the bert and LR layer. Note that we take the hidden layer output from BERT and not the CLS embedding. The CLS embedding does not generate any meaningful sentence embedding and BERT was specifically trained for the NSP task. As such, using the CLS embedding directly leads to worse results. We found that using the penultimate hidden layers gave us best results for this task.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ALszvbWE5Zc"
      },
      "source": [
        "# Let's define the training loop and model\n",
        "\n",
        "def get_bert_output(my_bert, input_ids, attention_mask):    \n",
        "    outputs = my_bert(input_ids, attention_mask=attention_mask)\n",
        "    hidden_states = outputs[2]\n",
        "    sent_embedding = hidden_states[11][:, 0:1, :].squeeze(1).cuda()\n",
        "    return sent_embedding\n",
        "\n",
        "\n",
        "class linearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(linearRegression, self).__init__()\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n",
        "\n",
        "    \n",
        "def run_new_method(my_bert, optimizer, regression_head, regression_optimizer, train_dataloader, test_dataloader, epochs=10, freeze_layers=False):\n",
        "    old_test_loss = float('inf')\n",
        "\n",
        "    # freeze_layers = \"0,1,2,3,4\"\n",
        "    if freeze_layers:\n",
        "        freeze_layers = \"0,1,2,3,4,5\"\n",
        "        layer_indexes = [int(x) for x in freeze_layers.split(\",\")]\n",
        "        for layer_idx in layer_indexes:\n",
        "            for param in list(my_bert.encoder.layer[layer_idx].parameters()):\n",
        "                param.requires_grad = False\n",
        "            print (\"Froze Layer: \", layer_idx)\n",
        "\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "        total_loss = 0\n",
        "        batch_count = 0\n",
        "        # put model in train mode\n",
        "        my_bert.train()\n",
        "        regression_head.train()\n",
        "        for step_num, batch_data in enumerate(train_dataloader):\n",
        "            input_ids = batch_data[\"input_ids\"].to(device)\n",
        "            attention_mask = batch_data[\"attention_mask\"].to(device)\n",
        "            score = batch_data[\"score\"].to(device)\n",
        "            score = score.unsqueeze(1)\n",
        "\n",
        "            my_bert_optimizer.zero_grad()\n",
        "            regression_optimizer.zero_grad()\n",
        "            bert_embedding = get_bert_output(my_bert, input_ids, attention_mask)\n",
        "            predicted_score = regression_head(bert_embedding)\n",
        "\n",
        "            loss_func = nn.MSELoss()\n",
        "            batch_loss = loss_func(predicted_score, score)\n",
        "\n",
        "            \n",
        "            batch_loss.backward()\n",
        "            my_bert_optimizer.step()\n",
        "            regression_optimizer.step()\n",
        "            total_loss += batch_loss.item()\n",
        "            batch_count += 1\n",
        "            train_loss = total_loss/batch_count\n",
        "        print(\"Epoch: {} Train Loss:{}\".format(epoch_num, train_loss))\n",
        "\n",
        "        # put model in test mode\n",
        "        my_bert.eval()\n",
        "        regression_head.eval()\n",
        "        test_loss = 0\n",
        "        test_batch_count = 0\n",
        "        with torch.no_grad():\n",
        "            for step_num, batch_data in enumerate(test_dataloader):\n",
        "                input_ids = batch_data[\"input_ids\"].to(device)\n",
        "                attention_mask = batch_data[\"attention_mask\"].to(device)\n",
        "                score = batch_data[\"score\"].to(device)\n",
        "                score = score.unsqueeze(1)\n",
        "\n",
        "                bert_embedding = get_bert_output(my_bert, input_ids, attention_mask)\n",
        "                predicted_score = regression_head(bert_embedding)\n",
        "\n",
        "                loss_func = nn.MSELoss()\n",
        "                batch_loss = loss_func(predicted_score, score)\n",
        "                test_loss += batch_loss.item()\n",
        "                test_batch_count += 1\n",
        "        # curr_test_loss = test_loss/test_batch_count\n",
        "        # print(\"Epoch: {} Test Loss:{}\\n\".format(epoch_num, curr_test_loss))\n",
        "        # if curr_test_loss < 0.61 or train_loss < 0.25:\n",
        "        #     print(\"yay, exit\")\n",
        "        #     break\n",
        "        curr_test_loss = test_loss/test_batch_count\n",
        "        print(\"dev loss: {}\\n\".format(curr_test_loss))\n",
        "        if curr_test_loss-old_test_loss >= 0.03 or curr_test_loss<0.61 or train_loss < 0.25:\n",
        "            print(\"new test loss is greater; breaking\")\n",
        "            break\n",
        "        old_test_loss = curr_test_loss\n",
        "    return my_bert, regression_head\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "    Method to evaluate and calculate pcc on dev/test dataset, and show terrible predictions\n",
        "'''\n",
        "def evaluate_model(model, regression_head, test_dataloader, show_bad_predictions=True, prediction_difference=2.0):\n",
        "\n",
        "    actual = list()\n",
        "    predicted = list()\n",
        "    og_data = list()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_batch_count = 0\n",
        "        test_loss =0\n",
        "        for step_num, batch_data in enumerate(test_dataloader):\n",
        "            input_ids = batch_data[\"input_ids\"].to(device)\n",
        "            attention_mask = batch_data[\"attention_mask\"].to(device)\n",
        "            score = batch_data[\"score\"].to(device)\n",
        "            score = score.unsqueeze(1)\n",
        "\n",
        "            bert_embedding = get_bert_output(model, input_ids, attention_mask)\n",
        "            predicted_score = regression_head(bert_embedding)\n",
        "\n",
        "            actual.extend(score.tolist())\n",
        "            predicted.extend(predicted_score.tolist())\n",
        "            original_samples = batch_data[\"og_sample\"]\n",
        "            og_data.extend(original_samples)\n",
        "\n",
        "    # show bad predictions in a table\n",
        "    table = Texttable()\n",
        "    table.add_row([\"Actual\", \"Predicted\", \"Difference\", \"Text Sample\"])\n",
        "\n",
        "    for act, pre, og_data in zip(actual, predicted, og_data):\n",
        "        if abs(pre[0]-act[0]) > prediction_difference:\n",
        "            og = og_data.og_sample.text_a + \"    |||    \" + og_data.og_sample.text_b\n",
        "            print(\"{:.2f}    {:.2f}          {:.2f}     {}\".format(act[0], pre[0], abs(pre[0]-act[0]), og))\n",
        "\n",
        "    print('\\n\\n\\n')\n",
        "    actual = [item[0] for item in actual]\n",
        "    predicted = [item[0] for item in predicted]\n",
        "\n",
        "    correlation, p_value = pearsonr(actual, predicted)\n",
        "    print(\"Correlation score: \", correlation)\n",
        "    r2_val = r2_score(actual, predicted)\n",
        "    print(\"R2 Score: \", r2_val)\n",
        "\n",
        "\n",
        "\n",
        "    d = {\"a\": actual, \"p\": predicted}\n",
        "    dx = pd.DataFrame(d)\n",
        "    dx.plot.hist(bins=20, alpha=0.25)\n",
        "    return correlation\n",
        "\n",
        "\n",
        "def get_optimizer_params(model):\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    opt_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "    return opt_parameters\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmbgDSEcH8Vw"
      },
      "source": [
        "SENT_TYPE = \"CLINICAL\"\n",
        "train_data, test_data = get_data(sent_type=SENT_TYPE)\n",
        "\n",
        "d = {\"Train Clinical\": train_data, \"Test Clinical\": test_data}\n",
        "dx = pd.DataFrame(d)\n",
        "ax1 = dx.plot.hist(bins=20, alpha=0.25)\n",
        "ax1.set_xlabel(\"Clinical Data Score Distribution\")\n",
        "\n",
        "\n",
        "SENT_TYPE = \"MEDICAL\"\n",
        "train_data, test_data = get_data(sent_type=SENT_TYPE)\n",
        "d = {\"Train Clinical\": train_data, \"Test Clinical\": test_data}\n",
        "dx = pd.DataFrame(d)\n",
        "ax1 = dx.plot.hist(bins=20, alpha=0.25)\n",
        "ax1.set_xlabel(\"Medical Data Score Distribution\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9u2XL6HB6AZ"
      },
      "source": [
        "## **Select the base model to fine tune, and pass it to the train loop**\n",
        "We then evaluate the PCC on the dev set.  \n",
        "Note: Only bad examples and scores are printed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWblCP_2hGlS"
      },
      "source": [
        "# BERT FINE TUNE ON CLINICAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxLPnCm1CCBK",
        "outputId": "a6b1dc24-6bc9-453b-de1c-8fd8d7caba72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "SENT_TYPE=\"CLINICAL\"\n",
        "MODEL = \"bert-base-uncased\"\n",
        "my_bert = BertModel.from_pretrained(MODEL, output_hidden_states=True)\n",
        "my_bert.cuda()\n",
        "\n",
        "regression_head = linearRegression().cuda()\n",
        "linear_regression_optimizer = torch.optim.Adam(regression_head.parameters(), lr=1e-5)\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL, output_hidden_states=True)\n",
        "train_dataloader, test_dataloader = load_data(tokenizer=tokenizer, batch_size=8, sent_type=SENT_TYPE)\n",
        "bert_config = BertConfig.from_pretrained(MODEL, output_hidden_states=True)\n",
        "my_bert_optimizer = AdamW(get_optimizer_params(my_bert), lr=1e-6)\n",
        "updated_model, regression_head = run_new_method(my_bert=my_bert, optimizer=my_bert_optimizer, # optimizer\n",
        "                                                regression_head=regression_head, \n",
        "                                                regression_optimizer=linear_regression_optimizer,\n",
        "                                                train_dataloader=train_dataloader,\n",
        "                                                test_dataloader=test_dataloader,\n",
        "                                                epochs=15)\n",
        "\n",
        "pcc = evaluate_model(updated_model, regression_head, test_dataloader)\n",
        "model_loc = \"/content/drive/My Drive/clinical-sts/models/{}-bert-{}-{:.4f}.pth\".format(SENT_TYPE, MODEL, pcc)\n",
        "regression_loc = \"/content/drive/My Drive/clinical-sts/models/{}-regression-{}-{:.4f}.pth\".format(SENT_TYPE, MODEL, pcc)\n",
        "torch.save(updated_model, model_loc)\n",
        "torch.save(regression_head, regression_loc)\n",
        "print(\"Saved at:\\n'{}'\\n'{}'\".format(model_loc, regression_loc))\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train Loss:3.298357872057844\n",
            "dev loss: 1.3038518281982225\n",
            "\n",
            "Epoch: 1 Train Loss:1.0394384941017185\n",
            "dev loss: 0.9704904159640565\n",
            "\n",
            "Epoch: 2 Train Loss:0.7530986299531327\n",
            "dev loss: 0.834207834347206\n",
            "\n",
            "Epoch: 3 Train Loss:0.609519286343345\n",
            "dev loss: 0.7518821424421143\n",
            "\n",
            "Epoch: 4 Train Loss:0.5164313142222386\n",
            "dev loss: 0.7156669142491677\n",
            "\n",
            "Epoch: 5 Train Loss:0.45017093197891006\n",
            "dev loss: 0.6987083650687161\n",
            "\n",
            "Epoch: 6 Train Loss:0.39937123556931814\n",
            "dev loss: 0.6929923291592037\n",
            "\n",
            "Epoch: 7 Train Loss:0.36061688523601604\n",
            "dev loss: 0.698101512320778\n",
            "\n",
            "Epoch: 8 Train Loss:0.32712502791373815\n",
            "dev loss: 0.6896761704017135\n",
            "\n",
            "Epoch: 9 Train Loss:0.2837253684281475\n",
            "dev loss: 0.6922246892662609\n",
            "\n",
            "Epoch: 10 Train Loss:0.2660764479526767\n",
            "dev loss: 0.6846528021509156\n",
            "\n",
            "Epoch: 11 Train Loss:0.24206237842639286\n",
            "dev loss: 0.676625757752096\n",
            "\n",
            "new test loss is greater; breaking\n",
            "3.00    -0.15          3.15     the patient is not currently experiencing numbness to the effected limb.    |||    the patient has intact sensation to fine touch over the deltoid bilaterally.\n",
            "2.00    4.08          2.08     patient's wife verbalized understanding and had no further questions or concerns at this time.    |||    no further questions or concerns at this time.\n",
            "3.45    0.76          2.69     goals : patient will demonstrate a 50% decrease in pain in 6 sessions for increased participation in life or work activities.    |||    patient will demonstrate and / or verbalize understanding of home exercise program in 6 sessions for improved self management of the condition.\n",
            "3.00    0.96          2.04     she denies shortness of breath or chest pain.    |||    patient has not had sore throat, shortness of breath, eye irritation, facial pain, ear pain.\n",
            "1.50    4.18          2.68     if you have any further questions or concerns, please contact our office.    |||    no questions or concerns at conclusion of treatment.\n",
            "2.00    -0.01          2.01     the patient appeared pleased with the orthotic adjustment.    |||    the patient has crutches and instructions were given to bring them with to the hospital.\n",
            "5.00    2.52          2.48     always use a thin towel between the ice and your skin when applying ice.    |||    place a towel between your skin and the ice pack.\n",
            "4.50    1.46          3.04     he was appreciative and had no other questions.    |||    patient was given the recommendations and she had no further concerns at this time.\n",
            "3.00    0.26          2.74     the patient has intact sensation to fine touch over the deltoid bilaterally.    |||    the patient is not currently experiencing numbness to the effected limb.\n",
            "2.00    4.13          2.13     no further questions or concerns at this time.    |||    patient's wife verbalized understanding and had no further questions or concerns at this time.\n",
            "3.45    0.73          2.72     patient will demonstrate and / or verbalize understanding of home exercise program in 6 sessions for improved self management of the condition.    |||    goals : patient will demonstrate a 50% decrease in pain in 6 sessions for increased participation in life or work activities.\n",
            "3.00    0.98          2.02     patient has not had sore throat, shortness of breath, eye irritation, facial pain, ear pain.    |||    she denies shortness of breath or chest pain.\n",
            "1.50    4.10          2.60     no questions or concerns at conclusion of treatment.    |||    if you have any further questions or concerns, please contact our office.\n",
            "2.00    -0.00          2.00     the patient has crutches and instructions were given to bring them with to the hospital.    |||    the patient appeared pleased with the orthotic adjustment.\n",
            "5.00    2.35          2.65     place a towel between your skin and the ice pack.    |||    always use a thin towel between the ice and your skin when applying ice.\n",
            "4.50    1.70          2.80     patient was given the recommendations and she had no further concerns at this time.    |||    he was appreciative and had no other questions.\n",
            "4.50    2.47          2.03     the patient tolerated the procedure well and then was taken to the general care floor following the procedure for continued observation and monitoring.    |||    she tolerated the procedure well and there no complications.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Correlation score:  0.8190994722863677\n",
            "R2 Score:  0.6486950407484822\n",
            "Saved at:\n",
            "'/content/drive/My Drive/clinical-sts/models/CLINICAL-bert-bert-base-uncased-0.8191.pth'\n",
            "'/content/drive/My Drive/clinical-sts/models/CLINICAL-regression-bert-base-uncased-0.8191.pth'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFDpF2aKhOEc"
      },
      "source": [
        "# BERT FINE TUNE ON MEDICAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCCwt3GxY16y",
        "outputId": "ccb92495-c5a1-4a68-faa7-2cb6f383386d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "SENT_TYPE=\"MEDICAL\"\n",
        "MODEL = \"bert-base-uncased\"\n",
        "my_bert = BertModel.from_pretrained(MODEL, output_hidden_states=True)\n",
        "my_bert.cuda()\n",
        "\n",
        "regression_head = linearRegression().cuda()\n",
        "linear_regression_optimizer = torch.optim.Adam(regression_head.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL, output_hidden_states=True)\n",
        "train_dataloader, test_dataloader = load_data(tokenizer=tokenizer, batch_size=8, sent_type=SENT_TYPE)\n",
        "bert_config = BertConfig.from_pretrained(MODEL, output_hidden_states=True)\n",
        "my_bert_optimizer = AdamW(get_optimizer_params(my_bert), lr=1e-5)\n",
        "updated_model, regression_head = run_new_method(my_bert=my_bert, optimizer=my_bert_optimizer, # optimizer\n",
        "                                                regression_head=regression_head, \n",
        "                                                regression_optimizer=linear_regression_optimizer,\n",
        "                                                train_dataloader=train_dataloader,\n",
        "                                                test_dataloader=test_dataloader,\n",
        "                                                epochs=5)\n",
        "\n",
        "pcc = evaluate_model(updated_model, regression_head, test_dataloader)\n",
        "model_loc = \"/content/drive/My Drive/clinical-sts/models/{}-bert-{}-{:.2f}.pth\".format(SENT_TYPE, MODEL, pcc)\n",
        "regression_loc = \"/content/drive/My Drive/clinical-sts/models/{}-regression-{}-{:.2f}.pth\".format(SENT_TYPE, MODEL, pcc)\n",
        "torch.save(updated_model, model_loc)\n",
        "torch.save(regression_head, regression_loc)\n",
        "print(\"Saved at:\\n'{}'\\n'{}'\".format(model_loc, regression_loc))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train Loss:1.0704144894099625\n",
            "dev loss: 0.7635194063186646\n",
            "\n",
            "Epoch: 1 Train Loss:0.5875688332026122\n",
            "dev loss: 0.7165670283138752\n",
            "\n",
            "Epoch: 2 Train Loss:0.4527077880062041\n",
            "dev loss: 0.9039846509695053\n",
            "\n",
            "new test loss is greater; breaking\n",
            "3.00    0.79          2.21     metformin [ glucophage ] 500 mg tablet 1 - 2 tablets by mouth two times a day.    |||    furosemide 40 mg tablet 1 tablet by mouth one time daily.\n",
            "3.00    0.77          2.23     furosemide 40 mg tablet 1 tablet by mouth one time daily.    |||    metformin [ glucophage ] 500 mg tablet 1 - 2 tablets by mouth two times a day.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Correlation score:  0.6022246804890707\n",
            "R2 Score:  0.18653735494519164\n",
            "Saved at:\n",
            "'/content/drive/My Drive/clinical-sts/models/MEDICAL-bert-bert-base-uncased-0.60.pth'\n",
            "'/content/drive/My Drive/clinical-sts/models/MEDICAL-regression-bert-base-uncased-0.60.pth'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATqUlEQVR4nO3df7BfdX3n8efLkBqCZIFwl6Zc6E1ZJ/xoa8QLhQG7lC7dVF2Nle2WAYetTNP6Y0bHztYfs7PVme2OndkW646/0oJiEZGKVGu1W1CoZSaACY0YCCwiUROCiVGMVH4IvveP78n2brg3+d4f5/u9957nY+Y795zzPT/eB5JXzv2czzmfVBWSpO543rALkCQNlsEvSR1j8EtSxxj8ktQxBr8kdcwRwy6gH8cff3yNjY0NuwxJWlC2bNny3aoaOXj5ggj+sbExNm/ePOwyJGlBSfLNyZbb1CNJHWPwS1LHGPyS1DELoo1fkoblxz/+MTt37uTJJ58cdilTWrZsGaOjoyxdurSv9Q1+STqEnTt3cvTRRzM2NkaSYZfzHFXFvn372LlzJ6tXr+5rG5t6JOkQnnzySVauXDkvQx8gCStXrpzWbyQGvyQdxnwN/QOmW5/BL0kdYxu/JE3Dpof2zen+zj1l5Zzurx8G/yI0mz+Yw/hDKGmwbOqRpHlu/fr1vOQlL+GMM85g48aNs96fV/ySNM9dffXVHHfccTzxxBOcddZZvOY1r2Hlypn/dm7wS9I89773vY+bbroJgG9/+9s8+OCDBr8kLVa33XYbt9xyC5s2bWL58uVccMEFs36K2DZ+SZrHfvCDH3DssceyfPly7r//fu64445Z77P1K/4kS4DNwK6qekWS1cD1wEpgC/Daqnq67TokaS4MuufbunXr+NCHPsRpp53GmjVrOOecc2a9z0E09bwZ2A6saOb/GLiyqq5P8iHgCuCDA6hDkhac5z//+XzhC1+Y03222tSTZBR4OfAXzXyAC4FPNatcA6xvswZJ0v+v7Tb+9wJ/APykmV8JPFZVzzTzO4ETW65BkjRBa8Gf5BXAnqraMsPtNyTZnGTz3r1757g6SequNq/4zwNemWQHvZu5FwJ/BhyT5MC9hVFg12QbV9XGqhqvqvGRkecMEi9JmqHWgr+q3lFVo1U1BvwW8KWquhS4Fbi4We1y4DNt1SBJeq5h9ON/G/DWJF+n1+Z/1RBqkKTOGsiTu1V1G3BbM/0N4OxBHFeS5tzD/zi3+1v90rndXx98cleSOsbgl6R5bMeOHZx66qlceumlnHbaaVx88cX86Ec/mtU+DX5JmuceeOAB3vCGN7B9+3ZWrFjBBz7wgVntz+CXpHnupJNO4rzzzgPgsssu4/bbb5/V/gx+SZrnem+7mXp+ugx+SZrnvvWtb7Fp0yYArrvuOs4///xZ7c+BWCRpOobQ/XLNmjW8//3v53Wvex2nn346r3/962e1P4Nfkua5I444gmuvvXbO9mdTjyR1jMEvSfPY2NgY27Ztm9N9GvySdBhVNewSDmm69Rn8knQIy5YtY9++ffM2/KuKffv2sWzZsr638eauJB3C6OgoO3fuZD4PCLVs2TJGR0f7Xt/gl6RDWLp0KatXrx52GXPKph5J6hiDX5I6ps3B1pcluSvJV5Pcm+TdzfKPJnk4ydbms7atGiRJz9VmG/9TwIVV9XiSpcDtSb7QfPdfqupTLR5bkjSF1oK/en2fHm9mlzaf+dkfSpI6pNU2/iRLkmwF9gA3V9WdzVd/lOSeJFcmef4U225IsjnJ5vncjUqSFppWg7+qnq2qtcAocHaSnwfeAZwKnAUcB7xtim03VtV4VY2PjIy0WaYkdcpAevVU1WPArcC6qtpdPU8BHwHOHkQNkqSeNnv1jCQ5ppk+ErgIuD/JqmZZgPXA3L59SJJ0SG326lkFXJNkCb1/YG6oqs8l+VKSESDAVuD3WqxBknSQNnv13AO8eJLlF7Z1TEnS4fnkriR1jMEvSR1j8EtSxxj8ktQxBr8kdYzBL0kdY/BLUscY/JLUMQa/JHWMwS9JHWPwS1LHGPyS1DEGvyR1jMEvSR1j8EtSxxj8ktQxbQ69uCzJXUm+muTeJO9ulq9OcmeSryf5ZJKfaqsGSdJztXnF/xRwYVW9CFgLrEtyDvDHwJVV9W+A7wNXtFiDJOkgrQV/9TzezC5tPgVcCHyqWX4NvQHXJUkD0mobf5IlSbYCe4CbgYeAx6rqmWaVncCJU2y7IcnmJJv37t3bZpmS1CmtBn9VPVtVa4FR4Gzg1Glsu7GqxqtqfGRkpLUaJalrBtKrp6oeA24FzgWOSXJE89UosGsQNUiSetrs1TOS5Jhm+kjgImA7vX8ALm5Wuxz4TFs1SJKe64jDrzJjq4Brkiyh9w/MDVX1uST3Adcn+e/APwFXtViDJOkgrQV/Vd0DvHiS5d+g194vSRoCn9yVpI4x+CWpYwx+SeoYg1+SOsbgl6SOMfglqWMMfknqGINfkjrG4JekjjH4Jalj+gr+JL/QdiGSpMHo94r/A834uW9I8q9arUiS1Kq+gr+qXgpcCpwEbElyXZKLWq1MktSKvtv4q+pB4L8CbwP+LfC+JPcn+Y22ipMkzb1+2/h/McmV9AZSuRD4D1V1WjN9ZYv1SZLmWL9X/P8LuBt4UVW9saruBqiqR+j9FvAcSU5KcmuS+5Lcm+TNzfJ3JdmVZGvzedlcnIgkqT/9DsTycuCJqnoWIMnzgGVV9aOq+ssptnkG+P2qujvJ0fTuDdzcfHdlVf3PWVUuSZqRfq/4bwGOnDC/vFk2paraPeE3gx/SayY6cSZFSpLmTr/Bv6yqHj8w00wv7/cgScboDcN4Z7PoTUnuSXJ1kmP73Y8kafb6Df5/TnLmgZkkLwGe6GfDJC8AbgTeUlX7gQ8CpwBrgd3An0yx3YYkm5Ns3rt3b59lSpIOp982/rcAf5XkESDATwP/6XAbJVlKL/Q/XlWfBqiq70z4/s+Bz022bVVtBDYCjI+PV591SpIOo6/gr6qvJDkVWNMseqCqfnyobZIEuArYXlV/OmH5qqra3cy+Gtg2/bIlSTPV7xU/wFnAWLPNmUmoqo8dYv3zgNcCX0uytVn2TuCSJGuBAnYAvzvdoiVJM9dX8Cf5S3rt8luBZ5vFBUwZ/FV1O71moYN9fpo1SpLmUL9X/OPA6VVlW7skLXD99urZRu+GriRpgev3iv944L4kdwFPHVhYVa9spSpJUmv6Df53tVmEJGlw+u3O+Q9JfhZ4YVXdkmQ5sKTd0iRJbej3tcy/A3wK+HCz6ETgr9sqSpLUnn5v7r6RXr/8/fD/BmX5120VJUlqT7/B/1RVPX1gJskR9PrxS5IWmH6D/x+SvBM4shlr96+Av2mvLElSW/oN/rcDe4Gv0XvFwueZYuQtSdL81m+vnp8Af958JEkLWL/v6nmYSdr0q+rn5rwiSVKrpvOungOWAf8ROG7uy5Ekta2vNv6q2jfhs6uq3ktvAHZJ0gLTb1PPmRNmn0fvN4DpvMtfkjRP9BveE8fFfYbeACq/OefVSJJa12+vnl+Z7o6TnERvoJYT6N0Y3lhVf5bkOOCT9Ebz2gH8ZlV9f7r7lyTNTL9NPW891PcTx9Sd4Bng96vq7iRHA1uS3Az8Z+CLVfWeJG+n94zA26ZXtiRppvp9gGsceD29l7OdCPwecCZwdPN5jqraXVV3N9M/BLY3274KuKZZ7Rpg/UyLlyRNX79t/KPAmU2Ak+RdwN9W1WX9bJxkDHgxcCdwQlXtbr56lF5T0GTbbAA2AJx88sl9lqlZe/gfZ77t6pfOXR0LxKaH9s1q+3NPWTlHlUj96/eK/wTg6QnzTzNFYB8syQuAG4G3VNX+id81Y/hO+rK3qtpYVeNVNT4yMtJnmZKkw+n3iv9jwF1Jbmrm1/MvzTVTSrKUXuh/vKo+3Sz+TpJVVbU7ySpgz3SLliTNXL8PcP0R8NvA95vPb1fV/zjUNkkCXAVsP+jm72eBy5vpy4HPTLdoSdLMTechrOXA/qr6SJKRJKur6uFDrH8e8Frga0m2NsveCbwHuCHJFcA38XkASRqofrtz/iG9nj1rgI8AS4Fr6YX7pKrqdiBTfP2r0ytTkjRX+r25+2rglcA/A1TVI0zRjVOSNL/1G/xPT+yBk+So9kqSJLWp3+C/IcmHgWOS/A5wCw7KIkkL0mHb+JveOZ8ETgX202vn/29VdXPLtUmSWnDY4K+qSvL5qvoFwLAflNk8Qcvpc1aGpMWn36aeu5Oc1WolkqSB6Lcf/y8BlyXZQa9nT+j9MvCLbRUmSWrHIYM/yclV9S3g3w+oHklSyw53xf/X9N7K+c0kN1bVawZRlCSpPYcL/olP3v5cm4VoEZjVDWk6+VpnaRgOd3O3ppiWJC1Qh7vif1GS/fSu/I9spuFfbu6uaLU6SdKcO2TwV9WSQRUiSRqMfvvxS5IWiem8j18LxIpH75j5xj8z89a7ex/Zf/iVDuGM1bPaXFKfvOKXpI5pLfiTXJ1kT5JtE5a9K8muJFubz8vaOr4kaXJtXvF/FFg3yfIrq2pt8/l8i8eXJE2iteCvqi8D32tr/5KkmRlGG/+bktzTNAUdO9VKSTYk2Zxk8969ewdZnyQtaoMO/g8CpwBrgd3An0y1YlVtrKrxqhofGRkZVH2StOgNNPir6jtV9WxV/YTe0I1nD/L4kqQBB3+SVRNmXw1sm2pdSVI7WnuAK8kngAuA45PsBP4QuCDJWnovfNsB/G5bx5ckTa614K+qSyZZfFVbx5O6ZtND+2a87bmnrJzDSrTQ+OSuJHWMwS9JHWPwS1LHGPyS1DG+lrlNsx2DVpJa4BW/JHWMwS9JHWPwS1LHGPyS1DEGvyR1jMEvSR1j8EtSxxj8ktQxBr8kdYzBL0kd01rwN4Op70mybcKy45LcnOTB5ueUg61LktrR5hX/R4F1By17O/DFqnoh8MVmXpI0QK0Ff1V9GfjeQYtfBVzTTF8DrG/r+JKkyQ26jf+EqtrdTD8KnDDVikk2JNmcZPPevXsHU50kdcDQbu5WVdEbdH2q7zdW1XhVjY+MjAywMkla3AYd/N9Jsgqg+blnwMeXpM4bdPB/Fri8mb4c+MyAjy9Jnddmd85PAJuANUl2JrkCeA9wUZIHgX/XzEuSBqi1oRer6pIpvvrVto6pDpvNMJerXzp3dUgLgE/uSlLHGPyS1DEGvyR1jMEvSR1j8EtSxxj8ktQxBr8kdYzBL0kdY/BLUse09uSutGDM5qlfTp+zMqRB8YpfkjrG4JekjjH4JaljDH5J6hhv7kpDtOmhfQvuuOeesnIOK9EweMUvSR0zlCv+JDuAHwLPAs9U1fgw6pCkLhpmU8+vVNV3h3h8Seokm3okqWOGdcVfwN8nKeDDVbXx4BWSbAA2AJx88skDLk9DMasnaIdjxaN3zGr7/T99zhxVIvVvWFf851fVmcCvA29M8ssHr1BVG6tqvKrGR0ZGBl+hJC1SQwn+qtrV/NwD3AScPYw6JKmLBh78SY5KcvSBaeDXgG2DrkOSumoYbfwnADclOXD866rq74ZQhyR10sCDv6q+Abxo0MeV5qPZ3Bwe1o1hn/pd+OzOKUkdY/BLUscY/JLUMQa/JHWMwS9JHWPwS1LHGPyS1DEGvyR1jMEvSR2z6MfcHeZThvc+sn/G257xMytmdeyumc1/64Vqtq+EHoZ7H53d9rN5WnlYTw3PdlzlNur2il+SOsbgl6SOMfglqWMMfknqGINfkjrG4JekjhlK8CdZl+SBJF9P8vZh1CBJXTWMMXeXAO8Hfh04HbgkyemDrkOSumoYV/xnA1+vqm9U1dPA9cCrhlCHJHXSMJ7cPRH49oT5ncAvHbxSkg3Ahmb28SQPzPB4xwPfneG2C1kXz7uL5wzdPO8unjNM/7x/drKF8/aVDVW1Edg42/0k2VxV43NQ0oLSxfPu4jlDN8+7i+cMc3few2jq2QWcNGF+tFkmSRqAYQT/V4AXJlmd5KeA3wI+O4Q6JKmTBt7UU1XPJHkT8L+BJcDVVXVvi4ecdXPRAtXF8+7iOUM3z7uL5wxzdN6pqrnYjyRpgfDJXUnqGINfkjpmUQd/F18NkeTqJHuSbBt2LYOS5KQktya5L8m9Sd487JralmRZkruSfLU553cPu6ZBSbIkyT8l+dywaxmUJDuSfC3J1iSbZ72/xdrG37wa4v8AF9F7SOwrwCVVdd9QC2tZkl8GHgc+VlU/P+x6BiHJKmBVVd2d5GhgC7B+Mf+/ThLgqKp6PMlS4HbgzVW18MZjnKYkbwXGgRVV9Yph1zMISXYA41U1Jw+tLeYr/k6+GqKqvgx8b9h1DFJV7a6qu5vpHwLb6T0hvmhVz+PN7NLmsziv4iZIMgq8HPiLYdeykC3m4J/s1RCLOgwEScaAFwN3DreS9jVNHluBPcDNVbXozxl4L/AHwE+GXciAFfD3SbY0r7OZlcUc/OqYJC8AbgTeUlX7h11P26rq2apaS+/p97OTLOqmvSSvAPZU1ZZh1zIE51fVmfTeavzGpkl3xhZz8PtqiA5p2rlvBD5eVZ8edj2DVFWPAbcC64ZdS8vOA17ZtHdfD1yY5NrhljQYVbWr+bkHuIleU/aMLebg99UQHdHc6LwK2F5VfzrsegYhyUiSY5rpI+l1Yrh/uFW1q6reUVWjVTVG7+/zl6rqsiGX1bokRzWdFkhyFPBrwKx67S3a4K+qZ4ADr4bYDtzQ8qsh5oUknwA2AWuS7ExyxbBrGoDzgNfSuwLc2nxeNuyiWrYKuDXJPfQucm6uqs50b+yYE4Dbk3wVuAv426r6u9nscNF255QkTW7RXvFLkiZn8EtSxxj8ktQxBr8kdYzBL0kdY/BLUscY/JLUMf8X0blTRE33BT0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXsSZy25hQQP"
      },
      "source": [
        "# BIO-BERT FINE TUNE ON CLINICAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOV712JuY_FP",
        "outputId": "5e419f74-2397-437b-dba7-8e1bb0d116f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "SENT_TYPE=\"CLINICAL\"\n",
        "MODEL = \"/content/drive/My Drive/clinical-sts/bio-bert/\"\n",
        "my_bert = BertModel.from_pretrained(MODEL, output_hidden_states=True)\n",
        "my_bert.cuda()\n",
        "\n",
        "regression_head = linearRegression().cuda()\n",
        "linear_regression_optimizer = torch.optim.Adam(regression_head.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL, output_hidden_states=True)\n",
        "train_dataloader, test_dataloader = load_data(tokenizer=tokenizer, batch_size=8, sent_type=SENT_TYPE)\n",
        "bert_config = BertConfig.from_pretrained(MODEL, output_hidden_states=True)\n",
        "my_bert_optimizer = AdamW(get_optimizer_params(my_bert), lr=1e-5)\n",
        "updated_model, regression_head = run_new_method(my_bert=my_bert, optimizer=my_bert_optimizer, # optimizer\n",
        "                                                regression_head=regression_head, \n",
        "                                                regression_optimizer=linear_regression_optimizer,\n",
        "                                                train_dataloader=train_dataloader,\n",
        "                                                test_dataloader=test_dataloader,\n",
        "                                                epochs=3)\n",
        "\n",
        "pcc = evaluate_model(updated_model, regression_head, test_dataloader)\n",
        "model_name = \"bio-bert\"\n",
        "model_loc = \"/content/drive/My Drive/clinical-sts/models/{}-bert-{}-{:.2f}.pth\".format(SENT_TYPE, model_name, pcc)\n",
        "regression_loc = \"/content/drive/My Drive/clinical-sts/models/{}-regression-{}-{:.2f}.pth\".format(SENT_TYPE, model_name, pcc)\n",
        "torch.save(updated_model, model_loc)\n",
        "torch.save(regression_head, regression_loc)\n",
        "print(\"Saved at:\\n'{}'\\n'{}'\".format(model_loc, regression_loc))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train Loss:1.2176987404900568\n",
            "dev loss: 0.6022303312578622\n",
            "\n",
            "new test loss is greater; breaking\n",
            "4.50    2.10          2.40     alert and oriented x 3. pleasant and cooperative.    |||    neurological : he is oriented to person, place, and time.\n",
            "3.00    0.52          2.48     the patient is not currently experiencing numbness to the effected limb.    |||    the patient has intact sensation to fine touch over the deltoid bilaterally.\n",
            "2.00    4.53          2.53     patient's wife verbalized understanding and had no further questions or concerns at this time.    |||    no further questions or concerns at this time.\n",
            "4.50    2.47          2.03     the past medical history, medications, allergies, family history and social history were reviewed and are present in the emr.    |||    the following portions of the patient's history were reviewed and updated as appropriate : social history, surgical history and problem list.\n",
            "3.45    1.32          2.13     goals : patient will demonstrate a 50% decrease in pain in 6 sessions for increased participation in life or work activities.    |||    patient will demonstrate and / or verbalize understanding of home exercise program in 6 sessions for improved self management of the condition.\n",
            "4.50    2.27          2.23     she tolerated the procedure well and there no complications.    |||    the patient tolerated the procedure well and then was taken to the general care floor following the procedure for continued observation and monitoring.\n",
            "4.50    2.37          2.13     neurological : he is oriented to person, place, and time.    |||    alert and oriented x 3. pleasant and cooperative.\n",
            "3.00    0.59          2.41     the patient has intact sensation to fine touch over the deltoid bilaterally.    |||    the patient is not currently experiencing numbness to the effected limb.\n",
            "2.00    4.47          2.47     no further questions or concerns at this time.    |||    patient's wife verbalized understanding and had no further questions or concerns at this time.\n",
            "3.45    1.17          2.28     patient will demonstrate and / or verbalize understanding of home exercise program in 6 sessions for improved self management of the condition.    |||    goals : patient will demonstrate a 50% decrease in pain in 6 sessions for increased participation in life or work activities.\n",
            "1.50    3.82          2.32     please refer to his note for full details.    |||    client has participated in ot biofeedback, please refer to ot biofeedback note for details.\n",
            "4.50    2.46          2.04     the patient tolerated the procedure well and then was taken to the general care floor following the procedure for continued observation and monitoring.    |||    she tolerated the procedure well and there no complications.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Correlation score:  0.8298643536160089\n",
            "R2 Score:  0.6871727000936276\n",
            "Saved at:\n",
            "'/content/drive/My Drive/clinical-sts/models/CLINICAL-bert-bio-bert-0.83.pth'\n",
            "'/content/drive/My Drive/clinical-sts/models/CLINICAL-regression-bio-bert-0.83.pth'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6XS3PXchTJX"
      },
      "source": [
        "# BIO-BERT FINE TUNE ON MEDICAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUPYH1dEiZfQ",
        "outputId": "af040f38-1814-4711-e9df-98a347bb28f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "SENT_TYPE=\"MEDICAL\"\n",
        "MODEL = \"/content/drive/My Drive/clinical-sts/bio-bert/\"\n",
        "my_bert = BertModel.from_pretrained(MODEL, output_hidden_states=True)\n",
        "my_bert.cuda()\n",
        "\n",
        "regression_head = linearRegression().cuda()\n",
        "linear_regression_optimizer = torch.optim.Adam(regression_head.parameters(), lr=1e-4)\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL, output_hidden_states=True)\n",
        "train_dataloader, test_dataloader = load_data(tokenizer=tokenizer, batch_size=8, sent_type=SENT_TYPE)\n",
        "bert_config = BertConfig.from_pretrained(MODEL, output_hidden_states=True)\n",
        "my_bert_optimizer = AdamW(get_optimizer_params(my_bert), lr=1e-5)\n",
        "updated_model, regression_head = run_new_method(my_bert=my_bert, optimizer=my_bert_optimizer, # optimizer\n",
        "                                                regression_head=regression_head, \n",
        "                                                regression_optimizer=linear_regression_optimizer,\n",
        "                                                train_dataloader=train_dataloader,\n",
        "                                                test_dataloader=test_dataloader,\n",
        "                                                epochs=3)\n",
        "\n",
        "pcc = evaluate_model(updated_model, regression_head, test_dataloader)\n",
        "model_name = \"bio-bert\"\n",
        "model_loc = \"/content/drive/My Drive/clinical-sts/models/{}-bert-{}-{:.2f}.pth\".format(SENT_TYPE, model_name, pcc)\n",
        "regression_loc = \"/content/drive/My Drive/clinical-sts/models/{}-regression-{}-{:.2f}.pth\".format(SENT_TYPE, model_name, pcc)\n",
        "torch.save(updated_model, model_loc)\n",
        "torch.save(regression_head, regression_loc)\n",
        "print(\"Saved at:\\n'{}'\\n'{}'\".format(model_loc, regression_loc))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train Loss:1.2410147082610208\n",
            "dev loss: 0.7762654032558203\n",
            "\n",
            "Epoch: 1 Train Loss:0.6183263180685825\n",
            "dev loss: 0.6620215158909559\n",
            "\n",
            "Epoch: 2 Train Loss:0.4827575686036563\n",
            "dev loss: 0.6456039138138294\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Correlation score:  0.6537074888172552\n",
            "R2 Score:  0.40395896874296544\n",
            "Saved at:\n",
            "'/content/drive/My Drive/clinical-sts/models/MEDICAL-bert-bio-bert-0.65.pth'\n",
            "'/content/drive/My Drive/clinical-sts/models/MEDICAL-regression-bio-bert-0.65.pth'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}